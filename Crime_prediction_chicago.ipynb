{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zEnoYNa8Ak6X",
        "outputId": "070d823d-82a3-4622-e519-82251016f06a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1o6K-3tam6E"
      },
      "source": [
        "##Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMpyR-0OWmmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ccf85fb-c721-493b-8e66-9b61d77c2db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RySYcJ3aqka"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQXUCb3vy1Jj"
      },
      "source": [
        "####Install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pDcmIz9y3rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fc1d90-c541-4bc3-bbc1-9e97b4ef079c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.5)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=477b98c53503d102171ac0a482e4f460e601ffaa22b0cf31bf844f6b004adb87\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTP-lCTofkgF"
      },
      "source": [
        "####Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXZ-3uAqW3Zr"
      },
      "outputs": [],
      "source": [
        "# For data processing\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "# For data processing and manipulation\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# For date calculations\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# For ploting data\n",
        "import IPython\n",
        "import IPython.display\n",
        "\n",
        "import itertools\n",
        "from itertools import cycle\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# For checking path\n",
        "import os , gc\n",
        "from os import path\n",
        "import csv\n",
        "import json\n",
        "\n",
        "\n",
        "from scipy.stats import hmean\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#tensorflow libs\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping , Callback\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import backend\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.layers import Dense , LSTM ,Dropout , PReLU , RepeatVector ,TimeDistributed, Attention\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical , plot_model\n",
        "from tensorflow.keras import regularizers, constraints, initializers, activations\n",
        "#from keras.layers.recurrent import Recurrent, _time_distributed_dense\n",
        "from tensorflow.keras.layers import SimpleRNN as Recurrent\n",
        "#from tensorflow.compat.v1.keras.layers import RNN \n",
        "\n",
        "from tensorflow.keras.layers import InputSpec\n",
        "\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhzccPIYRjjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd874aeb-9494-4d97-a5e0-491a35862513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vehYKMVF1_dZ"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z6fNKYJatbR"
      },
      "source": [
        "##Root Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0vvXBXtXY00"
      },
      "outputs": [],
      "source": [
        "# ROOTPATH = '/content/gdrive/MyDrive/Projects/Crime forcasting'\n",
        "ROOTPATH = '/content/gdrive/MyDrive/Colab Notebooks/ThesisFinal'\n",
        "PATH_IMAGE = ROOTPATH+'/images_chicago_attention/'\n",
        "PATH_DA = ROOTPATH+\"/datasets/chicago-crime/chicago_data_sf_2004_2017_for_da.csv\"\n",
        "PATH_MAIN = ROOTPATH + \"/datasets/chicago-crime/Crimes_-_2001_to_Present.csv\"\n",
        "PATH_PDA = ROOTPATH+\"/datasets/chicago-crime/chicago_data_sf_2004_2017_for_police_da.csv\"\n",
        "PATH_DA_CAT = ROOTPATH+\"/datasets/chicago-crime/chicago_data_sf_2004_2017_for_da_cat.csv\"\n",
        "PATH_WEATHER = ROOTPATH+\"/datasets/chicago-crime/weather_data_chicago_2004_2017.csv\"\n",
        "PATH_TEMP = ROOTPATH+\"/datasets/chicago-crime/temp_data_chicago_2004_2017.csv\"\n",
        "date_after = pd.to_datetime(\"1/1/2004  00:00:00 AM\")\n",
        "date_before = pd.to_datetime(\"1/1/2018  00:00:00 AM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzB8T0RwawN0"
      },
      "source": [
        "##Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRT49EembGhC"
      },
      "source": [
        "####Load the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.debugging.set_log_device_placement(False)\n",
        "gpus = tf.config.list_logical_devices('CPU')\n",
        "strategy = tf.distribute.MirroredStrategy(gpus)"
      ],
      "metadata": {
        "id": "tXlkJz_j07yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnNruIDGbFS7"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    dataset = pd.read_csv(PATH_DA)\n",
        "    dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXaIZ7L9z6IW"
      },
      "source": [
        "####Date Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPo0a2-Xa3-8"
      },
      "source": [
        "The data from 2004 to 2017 are taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbETJbB1l-xa"
      },
      "outputs": [],
      "source": [
        "date_after = pd.to_datetime(\"1/1/2004  00:00:00 AM\")\n",
        "date_before = pd.to_datetime(\"1/1/2018  00:00:00 AM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDEEoZtSXbCs"
      },
      "outputs": [],
      "source": [
        "# dataset['datetime'] = pd.to_datetime(dataset['Date']+' '+dataset['Time'])\n",
        "# dataset = dataset[(dataset.datetime>=date_after) & (dataset.datetime<date_before)]\n",
        "# dataset = dataset.sort_values(by = ['datetime'])\n",
        "\n",
        "# dataset = dataset[[\"datetime\",\"Date\",\"Category\",\"PdDistrict\"]]\n",
        "\n",
        "# dataset.to_csv(ROOTPATH+'/datasets/sf-crime/sf_crime_data_2004_2017.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOa2CIKnqFee"
      },
      "outputs": [],
      "source": [
        "# dataset = pd.read_csv(ROOTPATH+'/datasets/sf-crime/sf_crime_data_2004_2017.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76WmPOwO6oZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc88fa4d-84a4-42d4-d8b9-d289acdaffd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5071819, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dskVJdhGwQwa"
      },
      "source": [
        "####PdDistrict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DB-FW8noUWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e733f2-4db4-40a7-f3ad-de2444d05df2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataset['PdDistrict'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95xem_zRr0Je"
      },
      "outputs": [],
      "source": [
        "if(dataset['PdDistrict'].isnull().sum()):\n",
        "    dataset = dataset.drop( index= dataset.loc[dataset['PdDistrict'].isnull()].index[0]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdpx49uvr8C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec13020-7a3a-4326-fb9c-1973a7893b61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset['PdDistrict'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucl4Xq6PsCpK"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.reset_index(drop= True)\n",
        "dataset['datetime'] = dataset['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqNe_bZWscAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4ad66d-ecb9-4516-d35a-712a65bfd87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Police departement district =  24\n",
            "0         1.0\n",
            "33        2.0\n",
            "4         3.0\n",
            "8         4.0\n",
            "15        5.0\n",
            "3         6.0\n",
            "20        7.0\n",
            "5         8.0\n",
            "2         9.0\n",
            "6        10.0\n",
            "21       11.0\n",
            "54       12.0\n",
            "7        14.0\n",
            "9        15.0\n",
            "23       16.0\n",
            "17       17.0\n",
            "40       18.0\n",
            "29       19.0\n",
            "1        20.0\n",
            "55159    21.0\n",
            "113      22.0\n",
            "12       24.0\n",
            "11       25.0\n",
            "13211    31.0\n",
            "Name: PdDistrict, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "num_police_dept = dataset['PdDistrict'].nunique()\n",
        "print(\"Police departement district = \",num_police_dept)\n",
        "Police_dept_name = dataset['PdDistrict'].drop_duplicates().sort_values(ascending = True)\n",
        "print(Police_dept_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia6nF7t1w44c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3440d951-d03c-44b6-9601-f192af7f946a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Police Departments ID:Name Dict-> \n",
            " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0, 5: 6.0, 6: 7.0, 7: 8.0, 8: 9.0, 9: 10.0, 10: 11.0, 11: 12.0, 12: 14.0, 13: 15.0, 14: 16.0, 15: 17.0, 16: 18.0, 17: 19.0, 18: 20.0, 19: 21.0, 20: 22.0, 21: 24.0, 22: 25.0, 23: 31.0}\n",
            "Police Departments Name:ID Dict-> \n",
            " {1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 5, 7.0: 6, 8.0: 7, 9.0: 8, 10.0: 9, 11.0: 10, 12.0: 11, 14.0: 12, 15.0: 13, 16.0: 14, 17.0: 15, 18.0: 16, 19.0: 17, 20.0: 18, 21.0: 19, 22.0: 20, 24.0: 21, 25.0: 22, 31.0: 23}\n",
            "PdDID column -> \n",
            " 0           1.0\n",
            "1          20.0\n",
            "2           9.0\n",
            "3           6.0\n",
            "4           3.0\n",
            "           ... \n",
            "5071814     5.0\n",
            "5071815    12.0\n",
            "5071816    18.0\n",
            "5071817    19.0\n",
            "5071818    17.0\n",
            "Name: PdDID, Length: 5071819, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    # Dictionary for mapping id to name of the unique police department\n",
        "    Police_dept_id_name = {i:Police_dept_name.values[i] for i in range (num_police_dept)}\n",
        "    print(\"Police Departments ID:Name Dict-> \\n\",Police_dept_id_name)\n",
        "\n",
        "    # Dictionary for mapping name of the unique police department to id\n",
        "    Police_dept_name_id = {key:value for (value,key) in Police_dept_id_name.items()}\n",
        "    print(\"Police Departments Name:ID Dict-> \\n\",Police_dept_name_id)\n",
        "\n",
        "    # Update the new column of dataframe with the value of the list \n",
        "    dataset[\"PdDID\"] = dataset['PdDistrict']\n",
        "    print(\"PdDID column -> \\n\", dataset[\"PdDID\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_lQ2o8An3N3"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    dataset.to_csv(PATH_PDA,index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OcmPg5xEP4m"
      },
      "source": [
        "######Time series based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bbA4WUKoE1X"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    dataset1 = pd.read_csv(PATH_PDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYAzwn7lxRD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7ee96d-1e79-428b-b2ff-1255c5d9c61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5071819, 13)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    print(dataset1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkOXSNZmpIzW"
      },
      "outputs": [],
      "source": [
        "def processCategoryPd(df):\n",
        "    for col in df.columns:\n",
        "        col = str(col)\n",
        "        if(col=='Category'):\n",
        "            continue\n",
        "        if col=='datetime':\n",
        "            continue\n",
        "        if col=='PdDID':\n",
        "            continue\n",
        "        if col=='PdDistrict':\n",
        "            continue\n",
        "        df.drop(col , 1 , inplace=True)\n",
        "\n",
        "    Category = np.array(df['Category'].unique() , str)\n",
        "    Category.sort()\n",
        "    Category = Category.tolist()\n",
        "    #print(Category)\n",
        "    df['Category'] = df['Category'].apply(lambda x:float(Category.index(x)))\n",
        "    Y = pd.DataFrame(to_categorical(df['Category']))\n",
        "    df = df.join(Y , on=Y.index)\n",
        "    df['count'] = df['Category'].apply(lambda x:float(1))\n",
        "    df.drop('Category' , 1, inplace=True)\n",
        "    df.set_index(\"datetime\" , inplace = True)\n",
        "    df.index =  pd.to_datetime(df.index)\n",
        "    #df_sample = df.resample(sample).sum()\n",
        "    return df, Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXjspyS2pJDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753cf702-9727-4a4b-9d2b-d29eb02760c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    df1 = processCategoryPd(dataset1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFc77FUWpnkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c078ff5-9de7-4a78-f46e-59ecc4c0bf52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5071819, 34)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    df1 , Category1 = df1\n",
        "    print(df1.shape)\n",
        "    df1.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaO1aW8Rygop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd99f81e-c872-44e3-ee4c-a243e0c03466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(198647, 34)\n",
            "(222946, 34)\n",
            "(261296, 34)\n",
            "(293522, 34)\n",
            "(227875, 34)\n",
            "(298434, 34)\n",
            "(303855, 34)\n",
            "(350117, 34)\n",
            "(251525, 34)\n",
            "(219618, 34)\n",
            "(327624, 34)\n",
            "(244782, 34)\n",
            "(192801, 34)\n",
            "(224142, 34)\n",
            "(168056, 34)\n",
            "(146331, 34)\n",
            "(217509, 34)\n",
            "(223202, 34)\n",
            "(86015, 34)\n",
            "kom  21.0 (3, 34)\n",
            "(168455, 34)\n",
            "(150591, 34)\n",
            "(294309, 34)\n",
            "kom  31.0 (164, 34)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    all_datasets = {}\n",
        "    new_Police_dept_name = [] #dataset['PdDistrict'].drop_duplicates().sort_values(ascending = True)\n",
        "    for x in Police_dept_name:\n",
        "        tmp = df1[(df1.PdDistrict == x)]\n",
        "        if(tmp.shape[0]<200):\n",
        "            # print(\"kom \",  x , tmp.shape)\n",
        "            continue\n",
        "        new_Police_dept_name.append(x)\n",
        "\n",
        "        all_datasets[x] = tmp\n",
        "        # print(all_datasets[x].shape)\n",
        "    Police_dept_name = new_Police_dept_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6z-pEY1oKr5"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    dataset2 = pd.read_csv(PATH_PDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy5q8PXn3WiK"
      },
      "outputs": [],
      "source": [
        "def processCategory(df):\n",
        "    for col in df.columns:\n",
        "        col = str(col)\n",
        "        if(col=='Category'):\n",
        "            continue\n",
        "        if col=='datetime':\n",
        "            continue\n",
        "        df.drop(col , 1 , inplace=True)\n",
        "\n",
        "    Category = np.array(df['Category'].unique() , str)\n",
        "    Category.sort()\n",
        "    Category = Category.tolist()\n",
        "    df['Category'] = df['Category'].apply(lambda x:float(Category.index(x)))\n",
        "    Y = pd.DataFrame(to_categorical(df['Category']))\n",
        "    df = df.join(Y , on=Y.index)\n",
        "    df['count'] = df['Category'].apply(lambda x:float(1))\n",
        "    df.drop('Category' , 1, inplace=True)\n",
        "\n",
        "\n",
        "    df.set_index(\"datetime\" , inplace = True)\n",
        "    df.index =  pd.to_datetime(df.index)\n",
        "    return df, Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHWhDKAv3zlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1f6743-5fc3-4e8c-f309-9124b4a0907d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    df2 = processCategory(dataset2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbVhAI6432cY"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    df2 , Category2 = df2\n",
        "    df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pepYVEyJ0pWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3ffb4b-d1b5-458f-e79a-c399718e2bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5071819, 32)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    print(df2.shape)\n",
        "    df2.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iokk1rNvwYSm"
      },
      "source": [
        "####Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l3ptISm2H-Q"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    weather_dataset = pd.read_csv(PATH_WEATHER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlHwq38B2fcQ"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    temperature_dataset = pd.DataFrame(weather_dataset[[\"valid_date_time\", \"temp\"]].copy())\n",
        "    temperature_dataset = temperature_dataset.rename(columns={\"valid_date_time\": \"datetime\",\"temp\" : \"temperature\"})\n",
        "    temperature_dataset[\"datetime\"] = pd.to_datetime(temperature_dataset[\"datetime\"])\n",
        "    temperature_dataset = temperature_dataset.dropna()\n",
        "    temperature_dataset = temperature_dataset[(temperature_dataset.datetime>=date_after) & (temperature_dataset.datetime<date_before)]\n",
        "    temperature_dataset = temperature_dataset.drop_duplicates(subset =[\"datetime\"])\n",
        "    temperature_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22eo6ozWJ9SW"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    temperature_dataset[\"temperature\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8-pTWYl4b2e"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    temperature_dataset.to_csv(PATH_TEMP,index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhQesUzwCtEl"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    temperature_dataset[\"temperature\"].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v92CDmhDve_"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    temperature_dataset[\"temperature\"].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ZRPaVFfz0N"
      },
      "source": [
        "####Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBOS2gjkZeph"
      },
      "outputs": [],
      "source": [
        "def processData(df,sample):\n",
        "    '''\n",
        "    Change the sorted crime category with their index value\n",
        "    & Resample Date time using hour\n",
        "    input:\n",
        "        df  : Dataset to process\n",
        "        sample  : How to resample dataset df\n",
        "    output:\n",
        "        df_sample : resampled dataset df\n",
        "    '''\n",
        "\n",
        "    df_sample = df.resample(sample).sum()\n",
        "    return df_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIV50CdCq6x1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed4431a-1730-4b08-a082-e435e525ead0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 (122735, 34)\n",
            "2.0 (122735, 34)\n",
            "3.0 (122736, 34)\n",
            "4.0 (122736, 34)\n",
            "5.0 (122736, 34)\n",
            "6.0 (122736, 34)\n",
            "7.0 (122736, 34)\n",
            "8.0 (122736, 34)\n",
            "9.0 (122735, 34)\n",
            "10.0 (122736, 34)\n",
            "11.0 (122736, 34)\n",
            "12.0 (122736, 34)\n",
            "14.0 (122735, 34)\n",
            "15.0 (122735, 34)\n",
            "16.0 (122736, 34)\n",
            "17.0 (122736, 34)\n",
            "18.0 (122736, 34)\n",
            "19.0 (122736, 34)\n",
            "20.0 (122736, 34)\n",
            "22.0 (122736, 34)\n",
            "24.0 (122736, 34)\n",
            "25.0 (122735, 34)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        all_datasets[x] = processData(all_datasets[x] , '1H')\n",
        "        print(x , all_datasets[x].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drta7faYslA0"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        all_datasets[x]['PdDID']= Police_dept_name_id[x]\n",
        "        all_datasets[x] = pd.merge(all_datasets[x] , temperature_dataset , on='datetime')\n",
        "        all_datasets[x].set_index('datetime' , inplace=True)\n",
        "        all_datasets[x].index = pd.to_datetime(all_datasets[x].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EG7wBeg-KPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4795d2-3d49-4e09-d28f-d6821b1b949f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(121620, 35)\n",
            "(121620, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121620, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121620, 35)\n",
            "(121620, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121621, 35)\n",
            "(121620, 35)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        print(all_datasets[x].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Kr5Q2U4Ofw"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    df2 = processData(df2 , '1H')\n",
        "    df2.index = pd.to_datetime(df2.index)\n",
        "    df2 = pd.merge(df2 , temperature_dataset , on='datetime')\n",
        "    df2.set_index('datetime' , inplace=True)\n",
        "    df2.index = pd.to_datetime(df2.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb-IZlZ5okfX"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMX_8q2M86Q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f820fc20-b924-49c2-b4f6-af18ba52b907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(121621, 33)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    print(df2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7sHtwMVgPzc"
      },
      "source": [
        "####Time to signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNOc8V_Gk1D"
      },
      "source": [
        "As we are trying to work with the periodical nature of crime, we are using encoded cyclic feature.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bCAa6haZmoU"
      },
      "outputs": [],
      "source": [
        "def dateTimeToSignal(df):\n",
        "    '''\n",
        "    Converts the DateTime index to timestamp and convert it to signal (sine and cosine) to deal with periodicity\n",
        "    input: \n",
        "        df : Dataset\n",
        "    Output:\n",
        "        df : Dataset with column Day sin , Day cos , Week sin , Week cos ,  Year sin , Year cos ; representing Sin / Cosine signal for timestamp  \n",
        "    '''\n",
        "    timestamp_s = df.index.map(datetime.datetime.timestamp)\n",
        "    day = 24*60*60\n",
        "    week = 7*day\n",
        "    year = (365.2425)*day\n",
        "\n",
        "    df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "    df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "\n",
        "    df['Week sin'] = np.sin(timestamp_s * (2 * np.pi / week))\n",
        "    df['Week cos'] = np.cos(timestamp_s * (2 * np.pi / week))\n",
        "\n",
        "    df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "    df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoKhI8xA2N2k"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        all_datasets[x] = dateTimeToSignal(all_datasets[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7iHElV25uFA"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    df2 = dateTimeToSignal(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "was4VETex-2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d306090-796f-4368-94e9-ae90649031fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 (121620, 41)\n",
            "2.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "3.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "4.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "5.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "6.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "7.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "8.0 (121620, 41)\n",
            "9.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "10.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "11.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "12.0 (121620, 41)\n",
            "14.0 (121620, 41)\n",
            "15.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "16.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "17.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "18.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "19.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "20.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "22.0 (121620, 41)\n",
            "2017-12-31 23:00:00\n",
            "24.0 (121620, 41)\n",
            "25.0 (121620, 41)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    mini = 1000000000\n",
        "    common_date = None\n",
        "    for x in Police_dept_name:\n",
        "        # print(all_datasets[x].shape)\n",
        "        if all_datasets[x].shape[0] < mini:\n",
        "            mini = all_datasets[x].shape[0];\n",
        "            common_date = all_datasets[x].index\n",
        "\n",
        "    for x in Police_dept_name:\n",
        "        if(all_datasets[x].shape[0]>mini):\n",
        "            delItems = []\n",
        "            for i in all_datasets[x].index:\n",
        "                if(i not in common_date):\n",
        "                    delItems.append(i)\n",
        "                    # print(i)\n",
        "            all_datasets[x].drop(delItems , inplace=True)\n",
        "        # print(x , all_datasets[x].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tifnk12Bt-L"
      },
      "outputs": [],
      "source": [
        "# date_all = df2.index\n",
        "# date_range = pd.date_range(date_after,date_before)\n",
        "# for x in Police_dept_name:\n",
        "#   if(len(all_datasets[x])<len(date_all)):\n",
        "#     for i in date_all:\n",
        "#       if(i not in all_datasets[x].index):\n",
        "#         all_datasets[x].loc[i] = all_datasets[x].loc[date_after]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL4paTSNFg59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355e9859-b2b1-4b6e-be5e-2d9f3d850a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 (121620, 41)\n",
            "2.0 (121620, 41)\n",
            "3.0 (121620, 41)\n",
            "4.0 (121620, 41)\n",
            "5.0 (121620, 41)\n",
            "6.0 (121620, 41)\n",
            "7.0 (121620, 41)\n",
            "8.0 (121620, 41)\n",
            "9.0 (121620, 41)\n",
            "10.0 (121620, 41)\n",
            "11.0 (121620, 41)\n",
            "12.0 (121620, 41)\n",
            "14.0 (121620, 41)\n",
            "15.0 (121620, 41)\n",
            "16.0 (121620, 41)\n",
            "17.0 (121620, 41)\n",
            "18.0 (121620, 41)\n",
            "19.0 (121620, 41)\n",
            "20.0 (121620, 41)\n",
            "22.0 (121620, 41)\n",
            "24.0 (121620, 41)\n",
            "25.0 (121620, 41)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        print(x , all_datasets[x].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rapX8G1TgZec"
      },
      "source": [
        "####Group Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIK9SmPdSxYR"
      },
      "source": [
        "In the Dataset, there are many categories whose count is less then 100000 and the lowest count is 14. There are only 7 categories having count greater than 100000. So, we've taken this 7 categories as they are and then made 3 groups with rest of the categories.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0f-aeyZXd1m"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    # Group define\n",
        "    GROUPS = [[15],\n",
        "        [2],\n",
        "        [5],\n",
        "        [8],\n",
        "        [1],\n",
        "        [21],\n",
        "        [3],\n",
        "        [29,7],\n",
        "        [26,6],\n",
        "        [30,22,24,19,27,12,9,16,0,10,14,13,28,18,17,4,23,20,11,25]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17CJZjtKZ7V1"
      },
      "outputs": [],
      "source": [
        "def make_groups(df):\n",
        "    '''\n",
        "    Make 10 groups from 38 different type of crime categories. \n",
        "    Where,\n",
        "      GR0 consits of,\n",
        "        29 \tVEHICLE THEFT \n",
        "        7 \tDECEPTIVE PRACTICE\n",
        "      GR1 consits of,\n",
        "        26 \tROBBERY \n",
        "        6 \tCRIMINAL TRESPASS\n",
        "      GR2 consits of,\n",
        "        30 \tWEAPONS VIOLATION \t\t\n",
        "        22 \tPROSTITUTION \t\t\t\t\n",
        "        24 \tPUBLIC PEACE VIOLATION \t\t\n",
        "        19 \tOFFENSE INVOLVING CHILDREN \t\n",
        "        27 \tSEX OFFENSE \t\t\t\n",
        "        12 \tINTERFERENCE WITH PUBLIC OFFICER \t\n",
        "        9 \tGAMBLING \t\t\t\t\n",
        "        16 \tLIQUOR LAW VIOLATION \t\t\t\n",
        "        0 \tARSON \t\t\t\t  \t\n",
        "        10 \tHOMICIDE \t\t\t\t\n",
        "        14 \tKIDNAPPING \t\t\t\t\n",
        "        13 \tINTIMIDATION \t\t\t\t\n",
        "        28 \tSTALKING \t\t\t\t\n",
        "        18 \tOBSCENITY \t\t\t\t \n",
        "        17 \tNON-CRIMINAL \t\t\t\t \n",
        "        4 \tCONCEALED CARRY LICENSE VIOLATION \t \n",
        "        23 \tPUBLIC INDECENCY \t\t\t \n",
        "        20 \tOTHER NARCOTIC VIOLATION \t\t  \n",
        "        11 \tHUMAN TRAFFICKING \t\t\t  \n",
        "        25 \tRITUALISM \n",
        "\n",
        "    input:\n",
        "        df : Dataset with count of individual's from 38 categories\n",
        "    output:\n",
        "        df : Dataset with count of 10 groups  \n",
        "    '''\n",
        "    cnt = 0\n",
        "    for i in GROUPS:\n",
        "        cols_to_sum = i\n",
        "        if(len(i)==1):\n",
        "            continue\n",
        "        else:\n",
        "            newname = \"GRP\"+str(cnt)\n",
        "            cnt = cnt + 1\n",
        "            try:\n",
        "                df[newname] = df[cols_to_sum].sum(axis=1)\n",
        "                for j in i:\n",
        "                    df.drop(j , 1 , inplace=True)\n",
        "            except: \n",
        "                continue\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znDAsdbqZaLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ee9c06-268c-4889-805d-aab7cb2cac59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "6.0\n",
            "7.0\n",
            "8.0\n",
            "9.0\n",
            "10.0\n",
            "11.0\n",
            "12.0\n",
            "14.0\n",
            "15.0\n",
            "16.0\n",
            "17.0\n",
            "18.0\n",
            "19.0\n",
            "20.0\n",
            "22.0\n",
            "24.0\n",
            "25.0\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        print(x)\n",
        "        all_datasets[x] = make_groups(all_datasets[x])\n",
        "        all_datasets[x] = all_datasets[x].rename(columns={15:1,2: 2, 5 : 3,8 : 4,1 : 5,21 : 6,3 : 7})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5lEb7zM57rN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c07423-6b58-4d1b-aa91-dac369df155f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    df2 = make_groups(df2) \n",
        "    df2 = df2.rename(columns={15:1,\n",
        "                            2: 2,\n",
        "                            5 : 3,\n",
        "                            8 : 4,\n",
        "                            1 : 5,\n",
        "                            21 : 6,\n",
        "                            3 : 7})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-kqaOV9pZgC"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    names = {}\n",
        "    names['1'] = Category1[15]\n",
        "    names['2'] = Category1[2]\n",
        "    names['3'] = Category1[5]\n",
        "    names['4'] = Category1[8]\n",
        "    names['5'] = Category1[1]\n",
        "    names['6'] = Category1[21]\n",
        "    names['7'] = Category1[3]\n",
        "    names['count'] = 'COUNT'\n",
        "    names['GRP0'] = 'GRP0'\n",
        "    names['GRP1'] = 'GRP1'\n",
        "    names['GRP2'] = 'GRP2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Iffnj5k1jzh"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    df2.index = pd.to_datetime(df2.index)\n",
        "    df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV9Yp-Sd6PR_"
      },
      "source": [
        "####Temperature categorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxRJ8fc1IKBP"
      },
      "outputs": [],
      "source": [
        "def temp_scale(x):\n",
        "    '''\n",
        "    x <= 273K or 0C -> low(0) \n",
        "    x > 303K or 30C-> high(2)\n",
        "    else medium(1)\n",
        "    '''\n",
        "    if(x<=0):\n",
        "        return 0\n",
        "    elif(x>30):\n",
        "        return 2\n",
        "    else:\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o46losuIVV0"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    for x in Police_dept_name:\n",
        "        all_datasets[x]['temperature'] = all_datasets[x]['temperature'].apply(lambda x:temp_scale(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pek75M2qGYM5"
      },
      "source": [
        "##Some functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxzmVqXLZz1v"
      },
      "outputs": [],
      "source": [
        "def split_data(df):\n",
        "    '''\n",
        "    split the dataset ( train , val , test = (70 , 20 , 10)% )\n",
        "    input:\n",
        "        df : Dataset to split\n",
        "    output:\n",
        "        train_df : train dataset\n",
        "        val_df : validation dataset\n",
        "        test_df : test dataset\n",
        "        num_features : Number of features in dataset\n",
        "        column_indices : column_indices in dataset\n",
        "    '''\n",
        "    column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "    n = len(df)\n",
        "    train_df = df[0:int(n*0.7)]\n",
        "    val_df = df[int(n*0.7):int(n*0.9)]\n",
        "    test_df = df[int(n*0.9):]\n",
        "\n",
        "    num_features = df.shape[1]\n",
        "    return train_df , val_df , test_df , num_features , column_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7Rtfx5reFQ8X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class WindowGenerator():\n",
        "    '''\n",
        "    WindowGenerator Class\n",
        "    1. Split windows of features into a (features, labels) pairs.\n",
        "    2. Plot the content of the resulting windows.\n",
        "    3. Efficiently generate batches of these windows from the training, evaluation, and test data, using tf.data.Datasets S.\n",
        "    '''\n",
        "    def __init__(self, input_width, label_width, shift,\n",
        "               train_df, val_df, test_df,\n",
        "               label_columns=None , shuffle=False , batch_size = 64):\n",
        "        '''\n",
        "        The __init__ method includes all the necessary logic for the input and label indices.\n",
        "        Input: \n",
        "            input_width : input width / window size \n",
        "            label_width : output width\n",
        "            shift : size of window shifting forward\n",
        "            train_df : train dataset\n",
        "            val_df : validation dataset\n",
        "            test_df : test dataset\n",
        "            label_columns ( Default = None) : Label Columns\n",
        "            shuffle ( Default = False) : weather to shuffle data \n",
        "            batch_size (Default = 64) : Batch Size\n",
        "        Output: None\n",
        "        Example :\n",
        "            w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['count'])\n",
        "            w2\n",
        "\n",
        "        '''\n",
        "        # Store the raw data.\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.test_df = test_df\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Work out the label column indices.\n",
        "        self.label_columns = label_columns\n",
        "        if label_columns is not None:\n",
        "            self.label_columns_indices = {name: i for i, name in\n",
        "                                        enumerate(label_columns)}\n",
        "            \n",
        "        self.column_indices = {name: i for i, name in\n",
        "                            enumerate(train_df.columns)}\n",
        "\n",
        "\n",
        "        # Work out the window parameters.\n",
        "        self.input_width = input_width\n",
        "        self.label_width = label_width\n",
        "        self.shift = shift\n",
        "\n",
        "        self.total_window_size = input_width + shift\n",
        "\n",
        "        self.input_slice = slice(0, input_width) #(start , stop)\n",
        "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "        self.label_start = self.total_window_size - self.label_width\n",
        "        self.labels_slice = slice(self.label_start, None)\n",
        "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '\\n'.join([\n",
        "            f'Total window size: {self.total_window_size}',\n",
        "            f'Input indices: {self.input_indices}',\n",
        "            f'Label indices: {self.label_indices}',\n",
        "            f'Label column name(s): {self.label_columns}'])\n",
        "        \n",
        "    def split_window(self, features):\n",
        "        '''\n",
        "        Given a list consecutive inputs, the split_window method will convert them to a window of inputs and a window of labels.\n",
        "        \n",
        "        Input: \n",
        "            features : Stack of array of datas , used for splitting data to inputs and labels\n",
        "        Output:\n",
        "            inputs : nd Array splitted as input_width\n",
        "            labesl : nd Array splitted as label_width\n",
        "        Example :\n",
        "        # Stack three slices, the length of the total window:\n",
        "            example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "\n",
        "            example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "            print('All shapes are: (batch, time, features)')\n",
        "            print(f'Window shape: {example_window.shape}')\n",
        "            print(f'Inputs shape: {example_inputs.shape}')\n",
        "            print(f'labels shape: {example_labels.shape}')\n",
        "        '''\n",
        "        inputs = features[:, self.input_slice, :]\n",
        "        labels = features[:, self.labels_slice, :]\n",
        "        #taking only the labels that are presentin the label_columns\n",
        "        if self.label_columns is not None:\n",
        "            labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns],axis=-1)\n",
        "\n",
        "        # Slicing doesn't preserve static shape information, so set the shapes\n",
        "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "        inputs.set_shape([None, self.input_width, None])\n",
        "        labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def plot(self, model=None, plot_col='count', max_subplots=3):\n",
        "        '''\n",
        "            plot method that allows a simple visualization of the split window,\n",
        "            Input:\n",
        "                model (Default=None) : tensorflow model to evaluate \n",
        "                plot_col ( Default = 'count') : Name of column to evaluate\n",
        "                max_subplots ( Default = 3) : Maximum Number of subplotting\n",
        "            Output:\n",
        "                None\n",
        "            Example:\n",
        "                w2.plot()\n",
        "                w2.plot(plot_col=0) # label wont be shown as w2 config has only column , count \n",
        "\n",
        "        '''\n",
        "        inputs, labels = self.example\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plot_col_index = self.column_indices[plot_col]\n",
        "        max_n = min(max_subplots, len(inputs))\n",
        "        for n in range(max_n):\n",
        "            plt.subplot(max_n, 1, n+1)\n",
        "            plt.ylabel(f'{plot_col} [normed]')\n",
        "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "            if self.label_columns:\n",
        "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "            else:\n",
        "                label_col_index = plot_col_index\n",
        "\n",
        "            if label_col_index is None:\n",
        "                continue\n",
        "\n",
        "            plt.scatter(self.label_indices, labels[n, :, label_col_index],edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "            if model is not None:\n",
        "                predictions = model(inputs)\n",
        "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                        marker='X', edgecolors='k', label='Predictions',c='#ff7f0e', s=64)\n",
        "            if n == 0:\n",
        "                plt.legend()\n",
        "        plt.xlabel('Time [h]')\n",
        "\n",
        "    def make_dataset(self, data):\n",
        "        '''\n",
        "        make_dataset method will take a time series DataFrame and convert it to a\n",
        "            tf.data.Dataset of (input_window, label_window) pairs using the preprocessing.timeseries_dataset_from_array function.\n",
        "        Input:\n",
        "            data :  Input data to transform into (input_window , label_window)\n",
        "        Output:\n",
        "            ds : transformed dataset\n",
        "        '''\n",
        "        data = np.array(data, dtype=np.float32)\n",
        "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "            data=data,\n",
        "            targets=None,\n",
        "            sequence_length=self.total_window_size,\n",
        "            sequence_stride=1,\n",
        "            shuffle=self.shuffle,\n",
        "            batch_size=self.batch_size,)\n",
        "        ds = ds.map(self.split_window)\n",
        "        return ds\n",
        "    \n",
        "    \n",
        "    def create_dataset2(self , map_df , reshape=True):\n",
        "      x = []\n",
        "      y = []\n",
        "      for res in iter(map_df):\n",
        "        inputs, labels = res\n",
        "        if(len(inputs)==64):\n",
        "          x.append(inputs)\n",
        "          y.append(labels)\n",
        "      \n",
        "      x = np.array(x)\n",
        "      y = np.array(y)\n",
        "      if(reshape):\n",
        "        x = x.reshape(-1, x.shape[-2] , x.shape[-1])\n",
        "        y = y.reshape(-1 , y.shape[-2] , y.shape[-1])\n",
        "      return x , y\n",
        "    \n",
        "    '''\n",
        "    properties for accessing  training, validation and test data as tf.data.Datasets using the above make_dataset method.\n",
        "    Also a standard example batch for easy access and plotting\n",
        "    '''\n",
        "\n",
        "    @property\n",
        "    def train(self):\n",
        "        return self.make_dataset(self.train_df)\n",
        "\n",
        "    @property\n",
        "    def val(self):\n",
        "        return self.make_dataset(self.val_df)\n",
        "\n",
        "    @property\n",
        "    def test(self):\n",
        "        return self.make_dataset(self.test_df)\n",
        "    \n",
        "    \n",
        "    @property\n",
        "    def example(self):\n",
        "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "        result = getattr(self, '_example', None)\n",
        "        if result is None:\n",
        "            # No example batch was found, so get one from the `.train` dataset\n",
        "            result = next(iter(self.train))\n",
        "            # And cache it for next time\n",
        "            self._example = result\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esmoBs53cotg"
      },
      "outputs": [],
      "source": [
        "def create_data(train , test , val , columns):\n",
        "    '''\n",
        "    Create dataset from main train , test , val with given columns\n",
        "    '''\n",
        "    if(columns==None):\n",
        "        columns = train.columns\n",
        "    new_train = train[columns]\n",
        "    new_test = test[columns]\n",
        "    new_val = val[columns]\n",
        "    return new_train , new_test , new_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlWKvMA6crpm"
      },
      "outputs": [],
      "source": [
        "def save_history(history , path):\n",
        "    # convert the history.history dict to a pandas DataFrame:     \n",
        "    hist_df = pd.DataFrame(history.history) \n",
        "    # or save to csv: \n",
        "    hist_csv_file = path\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_json(f)\n",
        "\n",
        "def get_history(path):\n",
        "\twith open(path) as json_file:\n",
        "\t\tdata = json.load(json_file)\n",
        "\t\treturn data\n",
        "\n",
        "def save_model_weights(model , path):\n",
        "  model.save_weights(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uZntRriVvwVx"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, modelPath , historyPath , window=None, name=None , patience=10):\n",
        "    '''\n",
        "    Compile and fit a model\n",
        "    '''\n",
        "    modelPathPar = ROOTPATH+'/'+modelPath+'/'\n",
        "    historyPathPar = ROOTPATH+'/'+historyPath+'/'\n",
        "    if (name!=None):\n",
        "        # model_path = ROOTPATH+'/model_all_mae_swish/'+name\n",
        "        # history_path = ROOTPATH+'/history_all_mae_swish/'+name+\".json\"\n",
        "        model_path = modelPathPar+name\n",
        "        history_path = historyPathPar+name+\".json\"\n",
        "        \n",
        "        if not path.exists(modelPathPar):\n",
        "            os.makedirs(modelPathPar)\n",
        "        if not path.exists(historyPathPar):\n",
        "            os.makedirs(historyPathPar)\n",
        "\n",
        "    if (name!=None and path.exists(model_path)):\n",
        "      print(\"Loaded Pre Trained Model\")\n",
        "      modelOld = tf.keras.models.load_model(model_path)\n",
        "      model.set_weights(modelOld.get_weights())\n",
        "      del modelOld\n",
        "      history = get_history(history_path)\n",
        "      return model , history\n",
        "      \n",
        "    \n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience)\n",
        "    \n",
        "    history = model.fit(window.train, epochs=MAX_EPOCHS,validation_data=window.val,callbacks=[early_stopping])\n",
        "    if(name!=None):\n",
        "      model.save(model_path)\n",
        "      save_history(history , history_path)\n",
        "    return model , history.history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvLS4Qbz0-RC"
      },
      "outputs": [],
      "source": [
        "def sMAPE(y, y_pred):\n",
        "    epsilon = 0.1\n",
        "    summ = backend.maximum(backend.abs(y) + backend.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
        "    smape = backend.abs(y_pred - y) / summ * 2.0\n",
        "    return smape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74Jq0i9gIeF4"
      },
      "outputs": [],
      "source": [
        "def R_squared(y, y_pred):\n",
        "  residual = tf.reduce_sum(tf.square(tf.subtract(y, y_pred)))\n",
        "  total = tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y))))\n",
        "  r2 = tf.subtract(1.0, tf.divide(residual, total))\n",
        "  return r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "377k0IBYcs9Y"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 200\n",
        "plt.rcParams.update({'font.size': 30})\n",
        "metrics_name = [\"MAE\" , \"MSLE\" , \"MSE\" , \"SMAPE\" , \"R^2\"]\n",
        "\n",
        "def compileModel(model):\n",
        "    with strategy.scope():\n",
        "        model.compile(loss=tf.losses.MeanAbsoluteError(),optimizer=tf.optimizers.Adam(),\n",
        "                    metrics=[tf.metrics.MeanSquaredLogarithmicError() , tf.metrics.MeanSquaredError() , sMAPE , R_squared ])\n",
        "        return model   \n",
        "    \n",
        "def compile_and_fit_merged(model, train_1, train_2, val_1, val_2, train_y , val_y, name=None , patience=10):\n",
        "    '''\n",
        "    Compile and fit a model\n",
        "    '''\n",
        "    with strategy.scope():\n",
        "        if(name!=None):\n",
        "            model_path = ROOTPATH+'/model_chicago_merge/'+name\n",
        "            history_path = ROOTPATH+'/history_chicago_merge/'+name+\".json\"\n",
        "            model_plot_path = ROOTPATH+'/model_plot_merge/'+name+\".png\"\n",
        "            checkpoint_path = ROOTPATH+\"/checkpoint_chicago_merge/\"+name+\".ckpt\"\n",
        "        \n",
        "\n",
        "            #plot_model(model, model_plot_path, show_shapes=True , expand_nested=True)\n",
        "\n",
        "        if not path.exists(ROOTPATH+'/model_chicago_merge/'):\n",
        "            os.makedirs(ROOTPATH+'/model_chicago_merge/')\n",
        "        if not path.exists(ROOTPATH+'/history_chicago_merge/'):\n",
        "            os.makedirs(ROOTPATH+'/history_chicago_merge/')\n",
        "        if not path.exists(ROOTPATH+'/model_plot_merge/'):\n",
        "            os.makedirs(ROOTPATH + '/model_plot_merge/')\n",
        "        if not path.exists(ROOTPATH+\"/checkpoint_chicago_merge/\"):\n",
        "            os.makedirs(ROOTPATH+\"/checkpoint_chicago_merge/\")\n",
        "\n",
        "        \n",
        "        if(name!=None and path.exists(model_path)):\n",
        "            print(\"Loaded Pre Trained Model\")\n",
        "            modelOld = tf.keras.models.load_model(model_path ,  custom_objects={'sMAPE':sMAPE , \"R_squared\":R_squared})\n",
        "            model.set_weights(modelOld.get_weights())\n",
        "            del modelOld\n",
        "            history = get_history(history_path)\n",
        "            return model , history\n",
        "            \n",
        "        if(name!=None and path.exists(ROOTPATH+\"/checkpoint_chicago_merge/\")):\n",
        "            print(\"loaded weights\")\n",
        "            try:\n",
        "                model.load_weights(checkpoint_path)\n",
        "            except tf.errors.NotFoundError:\n",
        "                print(\"not found\")\n",
        "\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience , restore_best_weights = True)\n",
        "\n",
        "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "        # print(checkpoint_dir)\n",
        "\n",
        "        # Create a callback that saves the model's weights\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                    save_weights_only=True,\n",
        "                                                    verbose=1)\n",
        "        history = model.fit([train_1,train_2], train_y, batch_size=64, epochs=MAX_EPOCHS, validation_data=([val_1,val_2],val_y), callbacks=[early_stopping , cp_callback])\n",
        "        if(name!=None):\n",
        "            model.save(model_path)\n",
        "            save_history(history , history_path)\n",
        "        return model , history.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkFiLNQcDk0M"
      },
      "source": [
        "input-> features = [time_signal , count_of_last_24h ]\n",
        "\n",
        "prediction = [next_hour_count]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7uzdwuFp7Td"
      },
      "outputs": [],
      "source": [
        "general_indexs = ['PdDID' , 1,2,3,4,5,6,7,'count','temperature','Day sin','Day cos','Week sin','Week cos','Year sin','Year cos','GRP0','GRP1','GRP2']\n",
        "x_col = ['Day sin' , 'Day cos' , 'Year sin' , 'Year cos' , 'Week cos' , 'Week sin' ,'temperature' , 'datetime' , 'PdDID']\n",
        "\n",
        "def generate_window(df_now, ret_test = 0):\n",
        "    train_df , val_df , test_df , num_features_df , column_indices_df = split_data(df_now)\n",
        "    train_df , test_df , val_df = create_data(train_df , test_df , val_df , general_indexs)\n",
        "    y_col = [] \n",
        "\n",
        "    for i in train_df.columns:\n",
        "        if (i in x_col):\n",
        "            continue\n",
        "        y_col.append(i)\n",
        "    wide_window_all = WindowGenerator(train_df=train_df, test_df=test_df , val_df=val_df, \n",
        "        input_width=24, label_width=24, shift=1,\n",
        "        label_columns=y_col)\n",
        "    \n",
        "    if (ret_test == 1):\n",
        "      return wide_window_all, test_df\n",
        "    else:  \n",
        "      return wide_window_all   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzesSNGY7QlV"
      },
      "outputs": [],
      "source": [
        "general_indexs2 = [ 1,2,3,4,5,6,7,'count', 'Day sin' , 'Day cos' , 'Week cos' , 'Week sin', 'Year sin' , 'Year cos' , 'GRP0','GRP1','GRP2']\n",
        "\n",
        "x_col2 = ['Day sin' , 'Day cos' , 'Year sin' , 'Year cos' , 'Week cos' , 'Week sin' , 'datetime']\n",
        "\n",
        "def generate_window2(df_now):\n",
        "    train_df , val_df , test_df , num_features_df , column_indices_df = split_data(df_now)\n",
        "    train_df , test_df , val_df = create_data(train_df , test_df , val_df , general_indexs2)\n",
        "    \n",
        "    y_col = []\n",
        "    for i in train_df.columns:\n",
        "        if(i in x_col2):\n",
        "            continue\n",
        "        y_col.append(i)\n",
        "    wide_window_all = WindowGenerator(train_df=train_df, test_df=test_df , val_df=val_df, input_width=24, label_width=24, shift=1, label_columns=y_col)\n",
        "    \n",
        "    return wide_window_all    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CFoavXnM3Wf"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "from json import JSONEncoder\n",
        "class NumpyArrayEncoder(JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return JSONEncoder.default(self, obj)\n",
        "def save_json(filename , data):\n",
        "    with open(filename, 'w') as fp:\n",
        "        json.dump(data, fp, cls=NumpyArrayEncoder)\n",
        "        fp.close()\n",
        "def read_json(filename):\n",
        "    with open(filename) as fp:\n",
        "        dictdump = json.loads(fp.read())\n",
        "        fp.close()\n",
        "        return dictdump\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4tPJCGxNV5X"
      },
      "outputs": [],
      "source": [
        "def print_perf_val_perf(perf , val_perf):\n",
        "    print(f'{\"model\":50s}: Test   | Val')\n",
        "    for i in range(len(metrics_name)):\n",
        "        print(\"==================\",metrics_name[i],\"==================\")\n",
        "        for key in val_perf.keys():\n",
        "            print(f'{str(key):50s}: {perf[key][i]:0.4f} | {val_perf[key][i]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKpTMc8Lfyyu"
      },
      "source": [
        "##Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tODEX_t2U3Qn",
        "outputId": "8dbdb202-c8c8-466d-bca7-2782801a9835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_BiLSTM (InputLayer)   [(None, 24, 19)]          0         \n",
            "                                                                 \n",
            " bilstm1 (Bidirectional)     (None, 24, 256)           151552    \n",
            "                                                                 \n",
            " bilstm2 (Bidirectional)     (None, 24, 128)           164352    \n",
            "                                                                 \n",
            " TimeDisDenseLSTM (TimeDistr  (None, 24, 64)           8256      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24, 11)            715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,875\n",
            "Trainable params: 324,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    input_bi_lstm = keras.Input(shape=(24,19), name=\"input_BiLSTM\")\n",
        "    x_bd = (keras.layers.Bidirectional(tf.keras.layers.LSTM(128, activation = tf.keras.activations.swish ,return_sequences=True) , name=\"bilstm1\"))(input_bi_lstm)\n",
        "    x_bd = (keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation = tf.keras.activations.swish ,return_sequences=True) , name=\"bilstm2\"))(x_bd)\n",
        "    x_bd = (TimeDistributed(keras.layers.Dense(units=64, activation = tf.keras.activations.swish), name=\"TimeDisDenseLSTM\"))(x_bd)\n",
        "    output_bi_lstm = (keras.layers.Dense(units=11))(x_bd)\n",
        "    \n",
        "    bi_lstm_model_all_feature = keras.Model(\n",
        "        inputs=[input_bi_lstm],\n",
        "        outputs=[output_bi_lstm],\n",
        "    )\n",
        "    bi_lstm_model_all_feature.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2C1vDhwMhXm",
        "outputId": "21ad1c72-3725-4742-b0d0-41b4d5e6d6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_attn (InputLayer)     [(None, 24, 17)]          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 24, 256)          149504    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " Attention (SeqSelfAttention  (None, 24, 256)          65537     \n",
            " )                                                               \n",
            "                                                                 \n",
            " TimeDisDense2 (TimeDistribu  (None, 24, 64)           16448     \n",
            " ted)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 24, 11)            715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232,204\n",
            "Trainable params: 232,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    input_attn_lstm = keras.Input(shape=(24,17), name=\"input_attn\")\n",
        "    x_attn = (keras.layers.Bidirectional(tf.keras.layers.LSTM(128, activation = tf.keras.activations.swish ,return_sequences=True, name= \"bdLSTMAttn\")))(input_attn_lstm)\n",
        "    x_attn = (SeqSelfAttention(attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL, attention_activation='swish', name='Attention'))(x_attn)\n",
        "    # x_attn = (keras.layers.Dense(units=64, activation = tf.keras.activations.swish, name=\"TimeDisDense1\"))(x_attn)\n",
        "    x_attn = (TimeDistributed(keras.layers.Dense(units=64, activation = tf.keras.activations.swish), name=\"TimeDisDense2\"))(x_attn)\n",
        "    output_attn_lstm = (keras.layers.Dense(units=11))(x_attn)\n",
        "    \n",
        "    attn_lstm_model_common_feature = keras.Model(\n",
        "        inputs=[input_attn_lstm],\n",
        "        outputs=[output_attn_lstm],\n",
        "    )\n",
        "    attn_lstm_model_common_feature.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B2tafmbX9AQ",
        "outputId": "61c7ca64-ae8d-4626-f9a9-a8c3e147a5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_attn_all (InputLayer)  [(None, 24, 19)]         0         \n",
            "                                                                 \n",
            " LSTM_all_attn (LSTM)        (None, 24, 128)           75776     \n",
            "                                                                 \n",
            " Attention_all (SeqSelfAtten  (None, 24, 128)          16385     \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " TimeDisDense_all (Dense)    (None, 24, 64)            8256      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 24, 11)            715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,132\n",
            "Trainable params: 101,132\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    # not trainable Attn_LSTM model \n",
        "    input_attn_lstm_all = keras.Input(shape=(24,19), name=\"input_attn_all\")\n",
        "    x_attn_all = (tf.keras.layers.LSTM(128, activation = tf.keras.activations.swish ,return_sequences=True, name= \"LSTM_all_attn\"))(input_attn_lstm_all)\n",
        "    x_attn_all = (SeqSelfAttention(attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL, attention_activation='swish', name='Attention_all'))(x_attn_all)\n",
        "    x_attn_all = (keras.layers.Dense(units=64, activation = tf.keras.activations.swish, name=\"TimeDisDense_all\"))(x_attn_all)\n",
        "    # x_attn = (TimeDistributed(keras.layers.Dense(units=64, activation = tf.keras.activations.swish), name=\"TimeDisDense1\"))(x_attn)\n",
        "    output_attn_lstm_all = (keras.layers.Dense(units=11))(x_attn_all)\n",
        "    \n",
        "    attn_lstm_model_all_feature = keras.Model(\n",
        "        inputs=[input_attn_lstm_all],\n",
        "        outputs=[output_attn_lstm_all],\n",
        "    )\n",
        "    attn_lstm_model_all_feature.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJoBCI3s-Dun"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    window_all = {}\n",
        "    for x in Police_dept_name:\n",
        "        window_all[x] = generate_window(all_datasets[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD0HuqPd9zbd"
      },
      "outputs": [],
      "source": [
        "IDX_R_SQ = 4\n",
        "def processModelEvaluation(model_now , val_perf_now , perf_now):\n",
        "    for y in Police_dept_name:\n",
        "        wide_window_all = window_all[y]\n",
        "\n",
        "        val_performance_now = model_now.evaluate(wide_window_all.val)\n",
        "        performance_now = model_now.evaluate(wide_window_all.test)\n",
        "        if(y not in val_perf_now):\n",
        "            val_perf_now[y] = val_performance_now\n",
        "            perf_now[y] = performance_now\n",
        "            continue\n",
        "\n",
        "        for idx in range(len(metrics_name)):\n",
        "            if(idx==IDX_R_SQ):\n",
        "                val_perf_now[y][idx] = max(val_perf_now[y][idx] , val_performance_now[idx])\n",
        "                perf_now[y][idx] = max(perf_now[y][idx] , performance_now[idx])\n",
        "            else:\n",
        "                val_perf_now[y][idx] = min(val_perf_now[y][idx] , val_performance_now[idx])\n",
        "                perf_now[y][idx] = min(perf_now[y][idx] , performance_now[idx])\n",
        "    \n",
        "    return val_perf_now , perf_now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0Tr-7FKYDYr"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    # Load Attn_LSTM MODEL\n",
        "    val_performance_attn_all = {}\n",
        "    performance_attn_all = {}\n",
        "    # histories = {}\n",
        "    attn_lstm_model_all_feature = compileModel(attn_lstm_model_all_feature)\n",
        "    for x in Police_dept_name:\n",
        "        key = int(x)\n",
        "        wide_window_all = window_all[x]\n",
        "        x = str(x)\n",
        "        print(x)\n",
        "        gc.collect()\n",
        "        attn_lstm_model_all_feature , history  = compile_and_fit(attn_lstm_model_all_feature, \"model_chicago_attn\" , \"history_chicago_attn\" , name='Attn_LSTM_all_feature_'+x , window=wide_window_all)\n",
        "        histories[\"attn_all\"+x] = history\n",
        "        # print(attn_lstm_model_all_feature.summary())\n",
        "        # print(attn_lstm_model_all_feature.layers)\n",
        "\n",
        "        # val_performance_attn_all , performance_attn_all = processModelEvaluation(attn_lstm_model_all_feature , val_performance_attn_all , performance_attn_all)\n",
        "        \n",
        "        val_performance_attn_all[x] = attn_lstm_model_all_feature.evaluate(wide_window_all.val)\n",
        "        performance_attn_all[x] = attn_lstm_model_all_feature.evaluate(wide_window_all.test)\n",
        "\n",
        "        IPython.display.clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCzihGcxnNdT"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    performance_attn_all = read_json(ROOTPATH+\"/performance_attn_all_chicago.json\")\n",
        "    val_performance_attn_all = read_json(ROOTPATH+\"/val_performance_attn_all_chicago.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5TzoryQ4lm_",
        "outputId": "4ccd819c-22ae-4ad0-e3a6-ccfbb395c4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                                             : Test   | Val\n",
            "================== MAE ==================\n",
            "1.0                                               : 0.0290 | 0.0252\n",
            "2.0                                               : 0.0151 | 0.0151\n",
            "3.0                                               : 0.0232 | 0.0258\n",
            "4.0                                               : 0.0274 | 0.0323\n",
            "5.0                                               : 0.0329 | 0.0352\n",
            "6.0                                               : 0.0539 | 0.0536\n",
            "7.0                                               : 0.0635 | 0.0674\n",
            "8.0                                               : 0.0906 | 0.0938\n",
            "9.0                                               : 0.0894 | 0.0915\n",
            "10.0                                              : 0.1054 | 0.1010\n",
            "11.0                                              : 0.1410 | 0.1436\n",
            "12.0                                              : 0.1365 | 0.1307\n",
            "14.0                                              : 0.1312 | 0.1263\n",
            "15.0                                              : 0.1504 | 0.1569\n",
            "16.0                                              : 0.1605 | 0.1626\n",
            "17.0                                              : 0.1667 | 0.1638\n",
            "18.0                                              : 0.2363 | 0.2124\n",
            "19.0                                              : 0.2402 | 0.2365\n",
            "20.0                                              : 0.1792 | 0.1756\n",
            "22.0                                              : 0.2642 | 0.2652\n",
            "24.0                                              : 0.2663 | 0.2562\n",
            "25.0                                              : 0.3797 | 0.3853\n",
            "================== MSLE ==================\n",
            "1.0                                               : 0.0053 | 0.0047\n",
            "2.0                                               : 0.0049 | 0.0047\n",
            "3.0                                               : 0.0050 | 0.0052\n",
            "4.0                                               : 0.0056 | 0.0060\n",
            "5.0                                               : 0.0050 | 0.0051\n",
            "6.0                                               : 0.0071 | 0.0071\n",
            "7.0                                               : 0.0075 | 0.0081\n",
            "8.0                                               : 0.0102 | 0.0106\n",
            "9.0                                               : 0.0100 | 0.0103\n",
            "10.0                                              : 0.0123 | 0.0118\n",
            "11.0                                              : 0.0179 | 0.0185\n",
            "12.0                                              : 0.0162 | 0.0157\n",
            "14.0                                              : 0.0167 | 0.0164\n",
            "15.0                                              : 0.0234 | 0.0250\n",
            "16.0                                              : 0.0271 | 0.0273\n",
            "17.0                                              : 0.0305 | 0.0305\n",
            "18.0                                              : 0.0444 | 0.0408\n",
            "19.0                                              : 0.0512 | 0.0509\n",
            "20.0                                              : 0.0409 | 0.0398\n",
            "22.0                                              : 0.0694 | 0.0701\n",
            "24.0                                              : 0.0712 | 0.0689\n",
            "25.0                                              : 0.1065 | 0.1089\n",
            "================== MSE ==================\n",
            "1.0                                               : 0.0309 | 0.0197\n",
            "2.0                                               : 0.0170 | 0.0166\n",
            "3.0                                               : 0.0173 | 0.0187\n",
            "4.0                                               : 0.0209 | 0.0236\n",
            "5.0                                               : 0.0179 | 0.0181\n",
            "6.0                                               : 0.0294 | 0.0297\n",
            "7.0                                               : 0.0295 | 0.0331\n",
            "8.0                                               : 0.0433 | 0.0547\n",
            "9.0                                               : 0.0384 | 0.0439\n",
            "10.0                                              : 0.0519 | 0.0488\n",
            "11.0                                              : 0.0854 | 0.1046\n",
            "12.0                                              : 0.0713 | 0.0664\n",
            "14.0                                              : 0.0650 | 0.0618\n",
            "15.0                                              : 0.0815 | 0.0940\n",
            "16.0                                              : 0.0967 | 0.0975\n",
            "17.0                                              : 0.1043 | 0.0988\n",
            "18.0                                              : 0.2229 | 0.1814\n",
            "19.0                                              : 0.2158 | 0.2057\n",
            "20.0                                              : 0.1111 | 0.1058\n",
            "22.0                                              : 0.2351 | 0.2367\n",
            "24.0                                              : 0.2347 | 0.2162\n",
            "25.0                                              : 0.4441 | 0.4599\n",
            "================== SMAPE ==================\n",
            "1.0                                               : 0.0463 | 0.0445\n",
            "2.0                                               : 0.0241 | 0.0246\n",
            "3.0                                               : 0.0450 | 0.0505\n",
            "4.0                                               : 0.0510 | 0.0572\n",
            "5.0                                               : 0.0587 | 0.0648\n",
            "6.0                                               : 0.0774 | 0.0789\n",
            "7.0                                               : 0.0965 | 0.0990\n",
            "8.0                                               : 0.1271 | 0.1276\n",
            "9.0                                               : 0.1412 | 0.1413\n",
            "10.0                                              : 0.1720 | 0.1673\n",
            "11.0                                              : 0.2228 | 0.2280\n",
            "12.0                                              : 0.2261 | 0.2218\n",
            "14.0                                              : 0.2432 | 0.2399\n",
            "15.0                                              : 0.2948 | 0.3010\n",
            "16.0                                              : 0.3165 | 0.3186\n",
            "17.0                                              : 0.3395 | 0.3393\n",
            "18.0                                              : 0.3622 | 0.3576\n",
            "19.0                                              : 0.4015 | 0.4039\n",
            "20.0                                              : 0.4129 | 0.4136\n",
            "22.0                                              : 0.4837 | 0.4851\n",
            "24.0                                              : 0.4876 | 0.4878\n",
            "25.0                                              : 0.5676 | 0.5743\n",
            "================== R^2 ==================\n",
            "1.0                                               : 0.9652 | 0.9617\n",
            "2.0                                               : 0.9578 | 0.9558\n",
            "3.0                                               : 0.9599 | 0.9604\n",
            "4.0                                               : 0.9616 | 0.9620\n",
            "5.0                                               : 0.9563 | 0.9557\n",
            "6.0                                               : 0.9545 | 0.9543\n",
            "7.0                                               : 0.9404 | 0.9451\n",
            "8.0                                               : 0.9351 | 0.9334\n",
            "9.0                                               : 0.9068 | 0.9098\n",
            "10.0                                              : 0.8881 | 0.8919\n",
            "11.0                                              : 0.8924 | 0.9019\n",
            "12.0                                              : 0.8637 | 0.8541\n",
            "14.0                                              : 0.8148 | 0.7981\n",
            "15.0                                              : 0.7552 | 0.7824\n",
            "16.0                                              : 0.6677 | 0.6770\n",
            "17.0                                              : 0.5699 | 0.5606\n",
            "18.0                                              : 0.6495 | 0.5907\n",
            "19.0                                              : 0.5182 | 0.5127\n",
            "20.0                                              : 0.8211 | 0.8176\n",
            "22.0                                              : 0.8022 | 0.7995\n",
            "24.0                                              : 0.7823 | 0.7995\n",
            "25.0                                              : 0.7669 | 0.7843\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    print_perf_val_perf(performance_attn_all , val_performance_attn_all)\n",
        "    save_json(ROOTPATH+\"/val_performance_attn_all_chicago.json\" , val_performance_attn_all)\n",
        "    save_json(ROOTPATH+\"/performance_attn_all_chicago.json\" , performance_attn_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhuRzITd42IC"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    # Load st-Bi_LSTM MODEL\n",
        "    val_performance_bd = {}\n",
        "    performance_bd = {}\n",
        "    histories = {}\n",
        "    bi_lstm_model_all_feature = compileModel(bi_lstm_model_all_feature)\n",
        "    for x in Police_dept_name:\n",
        "        wide_window_all = generate_window(all_datasets[x])\n",
        "        if(x<25.0):\n",
        "            continue\n",
        "        x = str(x)\n",
        "        print(x)\n",
        "        bi_lstm_model_all_feature , history  = compile_and_fit(\n",
        "            bi_lstm_model_all_feature, \"model_chicago_bd_all\" , \"history_chicago_attn\" , name='bd_LSTM_all_feature_'+x , window=wide_window_all)\n",
        "        histories['bd_'+x] = history\n",
        "        # print(attn_lstm_model_all_feature.summary())\n",
        "        # print(attn_lstm_model_all_feature.layers)\n",
        "        val_performance_bd[x] = bi_lstm_model_all_feature.evaluate(wide_window_all.val)\n",
        "        performance_bd[x] = bi_lstm_model_all_feature.evaluate(wide_window_all.test)\n",
        "\n",
        "        IPython.display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UlzapeZnoML"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    performance_bd = read_json(ROOTPATH+\"/performance_bd_all_chicago.json\")\n",
        "    val_performance_bd = read_json(ROOTPATH+\"/val_performance_bd_all_chicago.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pzh6X4P5P1s",
        "outputId": "09882224-3d48-41ac-d305-7b319bd55e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                                             : Test   | Val\n",
            "================== MAE ==================\n",
            "1.0                                               : 0.0923 | 0.0777\n",
            "2.0                                               : 0.0580 | 0.0533\n",
            "3.0                                               : 0.0436 | 0.0469\n",
            "4.0                                               : 0.0269 | 0.0286\n",
            "5.0                                               : 0.0179 | 0.0183\n",
            "6.0                                               : 0.0226 | 0.0225\n",
            "7.0                                               : 0.0204 | 0.0221\n",
            "8.0                                               : 0.0226 | 0.0233\n",
            "9.0                                               : 0.0168 | 0.0177\n",
            "10.0                                              : 0.0176 | 0.0176\n",
            "11.0                                              : 0.0222 | 0.0240\n",
            "12.0                                              : 0.0180 | 0.0167\n",
            "14.0                                              : 0.0132 | 0.0126\n",
            "15.0                                              : 0.0134 | 0.0149\n",
            "16.0                                              : 0.0134 | 0.0133\n",
            "17.0                                              : 0.0105 | 0.0101\n",
            "18.0                                              : 0.0156 | 0.0130\n",
            "19.0                                              : 0.0168 | 0.0168\n",
            "20.0                                              : 0.0069 | 0.0067\n",
            "22.0                                              : 0.0104 | 0.0106\n",
            "24.0                                              : 0.0098 | 0.0092\n",
            "25.0                                              : 0.0165 | 0.0175\n",
            "================== MSLE ==================\n",
            "1.0                                               : 0.0399 | 0.0339\n",
            "2.0                                               : 0.0240 | 0.0217\n",
            "3.0                                               : 0.0151 | 0.0166\n",
            "4.0                                               : 0.0046 | 0.0048\n",
            "5.0                                               : 0.0037 | 0.0037\n",
            "6.0                                               : 0.0048 | 0.0047\n",
            "7.0                                               : 0.0042 | 0.0045\n",
            "8.0                                               : 0.0048 | 0.0049\n",
            "9.0                                               : 0.0038 | 0.0040\n",
            "10.0                                              : 0.0039 | 0.0038\n",
            "11.0                                              : 0.0050 | 0.0049\n",
            "12.0                                              : 0.0040 | 0.0038\n",
            "14.0                                              : 0.0033 | 0.0031\n",
            "15.0                                              : 0.0034 | 0.0036\n",
            "16.0                                              : 0.0030 | 0.0031\n",
            "17.0                                              : 0.0027 | 0.0026\n",
            "18.0                                              : 0.0035 | 0.0031\n",
            "19.0                                              : 0.0035 | 0.0034\n",
            "20.0                                              : 0.0018 | 0.0017\n",
            "22.0                                              : 0.0029 | 0.0029\n",
            "24.0                                              : 0.0027 | 0.0025\n",
            "25.0                                              : 0.0043 | 0.0045\n",
            "================== MSE ==================\n",
            "1.0                                               : 0.1154 | 0.0886\n",
            "2.0                                               : 0.0603 | 0.0551\n",
            "3.0                                               : 0.0397 | 0.0447\n",
            "4.0                                               : 0.0165 | 0.0181\n",
            "5.0                                               : 0.0123 | 0.0125\n",
            "6.0                                               : 0.0177 | 0.0178\n",
            "7.0                                               : 0.0150 | 0.0170\n",
            "8.0                                               : 0.0188 | 0.0199\n",
            "9.0                                               : 0.0129 | 0.0139\n",
            "10.0                                              : 0.0134 | 0.0132\n",
            "11.0                                              : 0.0204 | 0.0231\n",
            "12.0                                              : 0.0151 | 0.0134\n",
            "14.0                                              : 0.0111 | 0.0100\n",
            "15.0                                              : 0.0107 | 0.0125\n",
            "16.0                                              : 0.0096 | 0.0098\n",
            "17.0                                              : 0.0082 | 0.0076\n",
            "18.0                                              : 0.0160 | 0.0120\n",
            "19.0                                              : 0.0130 | 0.0123\n",
            "20.0                                              : 0.0045 | 0.0043\n",
            "22.0                                              : 0.0088 | 0.0089\n",
            "24.0                                              : 0.0081 | 0.0072\n",
            "25.0                                              : 0.0154 | 0.0163\n",
            "================== SMAPE ==================\n",
            "1.0                                               : 0.1437 | 0.1262\n",
            "2.0                                               : 0.0973 | 0.0898\n",
            "3.0                                               : 0.0716 | 0.0767\n",
            "4.0                                               : 0.0407 | 0.0428\n",
            "5.0                                               : 0.0288 | 0.0292\n",
            "6.0                                               : 0.0346 | 0.0345\n",
            "7.0                                               : 0.0315 | 0.0335\n",
            "8.0                                               : 0.0331 | 0.0341\n",
            "9.0                                               : 0.0264 | 0.0276\n",
            "10.0                                              : 0.0261 | 0.0261\n",
            "11.0                                              : 0.0307 | 0.0315\n",
            "12.0                                              : 0.0278 | 0.0265\n",
            "14.0                                              : 0.0202 | 0.0198\n",
            "15.0                                              : 0.0209 | 0.0222\n",
            "16.0                                              : 0.0208 | 0.0209\n",
            "17.0                                              : 0.0166 | 0.0163\n",
            "18.0                                              : 0.0194 | 0.0176\n",
            "19.0                                              : 0.0237 | 0.0239\n",
            "20.0                                              : 0.0137 | 0.0136\n",
            "22.0                                              : 0.0157 | 0.0160\n",
            "24.0                                              : 0.0159 | 0.0155\n",
            "25.0                                              : 0.0225 | 0.0235\n",
            "================== R^2 ==================\n",
            "1.0                                               : 0.8435 | 0.8235\n",
            "2.0                                               : 0.8507 | 0.8557\n",
            "3.0                                               : 0.9076 | 0.9052\n",
            "4.0                                               : 0.9695 | 0.9708\n",
            "5.0                                               : 0.9694 | 0.9697\n",
            "6.0                                               : 0.9724 | 0.9723\n",
            "7.0                                               : 0.9694 | 0.9719\n",
            "8.0                                               : 0.9719 | 0.9734\n",
            "9.0                                               : 0.9687 | 0.9701\n",
            "10.0                                              : 0.9699 | 0.9698\n",
            "11.0                                              : 0.9737 | 0.9761\n",
            "12.0                                              : 0.9716 | 0.9708\n",
            "14.0                                              : 0.9687 | 0.9672\n",
            "15.0                                              : 0.9680 | 0.9710\n",
            "16.0                                              : 0.9672 | 0.9677\n",
            "17.0                                              : 0.9664 | 0.9664\n",
            "18.0                                              : 0.9753 | 0.9733\n",
            "19.0                                              : 0.9716 | 0.9714\n",
            "20.0                                              : 0.9623 | 0.9615\n",
            "22.0                                              : 0.9669 | 0.9678\n",
            "24.0                                              : 0.9668 | 0.9665\n",
            "25.0                                              : 0.9710 | 0.9721\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    print_perf_val_perf(performance_bd , val_performance_bd)\n",
        "    save_json(ROOTPATH+\"/val_performance_bd_all_chicago.json\" , val_performance_bd)\n",
        "    save_json(ROOTPATH+\"/performance_bd_all_chicago.json\" , performance_bd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRFHCkc5nTJz"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    for i in range(len(bi_lstm_model_all_feature.layers)):\n",
        "        bi_lstm_model_all_feature.layers[i].trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfe14PsNybW0",
        "outputId": "772f51d4-8266-4bec-dc2e-37a2de4f58d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_BiLSTM (InputLayer)   [(None, 24, 19)]          0         \n",
            "                                                                 \n",
            " bilstm1 (Bidirectional)     (None, 24, 256)           151552    \n",
            "                                                                 \n",
            " bilstm2 (Bidirectional)     (None, 24, 128)           164352    \n",
            "                                                                 \n",
            " TimeDisDenseLSTM (TimeDistr  (None, 24, 64)           8256      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,160\n",
            "Trainable params: 0\n",
            "Non-trainable params: 324,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    # Necessary part of Attn-LSTM for merged model\n",
        "    bi_lstm_model_all_feature_A = keras.Model(\n",
        "        inputs= bi_lstm_model_all_feature.inputs,\n",
        "        outputs= bi_lstm_model_all_feature.layers[-2].output\n",
        "    )\n",
        "\n",
        "    bi_lstm_model_all_feature_A.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0gjtWYj-p5k",
        "outputId": "785909e9-8629-471c-f340-1c02e74444c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_attn (InputLayer)     [(None, 24, 17)]          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 24, 256)          149504    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " Attention (SeqSelfAttention  (None, 24, 256)          65537     \n",
            " )                                                               \n",
            "                                                                 \n",
            " TimeDisDense2 (TimeDistribu  (None, 24, 64)           16448     \n",
            " ted)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 24, 11)            715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232,204\n",
            "Trainable params: 232,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    attn_lstm_model_common_feature.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQLRLQAsxMby",
        "outputId": "c02732f1-cf5f-481e-9141-7d54a7d6c874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is Loaded!!\n",
            "380/380 [==============================] - 38s 91ms/step - loss: 1.3049 - mean_squared_logarithmic_error: 0.2063 - mean_squared_error: 3.8324 - sMAPE: 0.5655 - R_squared: 0.9597\n",
            "190/190 [==============================] - 13s 69ms/step - loss: 1.3166 - mean_squared_logarithmic_error: 0.2175 - mean_squared_error: 3.7001 - sMAPE: 0.5713 - R_squared: 0.9598\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    val_performance_attn = {}\n",
        "    performance_attn = {}\n",
        "    wide_window2 = generate_window2(df2)\n",
        "\n",
        "    attn_lstm_model_common_feature = compileModel(attn_lstm_model_common_feature)\n",
        "\n",
        "    attn_lstm_model_common_feature , history_bd  = compile_and_fit(attn_lstm_model_common_feature,\"model_chicago_common_attn_mae_swish\" , \"history_chicago_common_attn_mae_swish\", name='attn_chicago_common_feature' , window=wide_window2)\n",
        "    IPython.display.clear_output()\n",
        "    print(\"Model is Loaded!!\")\n",
        "\n",
        "    val_performance_attn['attn_LSTM_common_feature'] = attn_lstm_model_common_feature.evaluate(wide_window2.val)\n",
        "    performance_attn['attn_LSTM_common_feature'] = attn_lstm_model_common_feature.evaluate(wide_window2.test)\n",
        "# save_json(ROOTPATH+\"/val_chicago_attn_LSTM_common_feature.json\"  , val_performance_attn)\n",
        "# save_json(ROOTPATH+\"/chicago_attn_LSTM_common_feature.json\" , performance_attn)\n",
        "# IPython.display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    val_performance_attn = read_json(ROOTPATH+\"/val_chicago_attn_LSTM_common_feature.json\")\n",
        "    performance_attn = read_json(ROOTPATH+\"/chicago_attn_LSTM_common_feature.json\")"
      ],
      "metadata": {
        "id": "_jBBSdRACnoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQawgGK7GTyN",
        "outputId": "325d0e85-653f-4c6b-eec7-ab64e5f40030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                                             : Test   | Val\n",
            "================== MAE ==================\n",
            "attn_LSTM_common_feature                          : 1.3166 | 1.3049\n",
            "================== MSLE ==================\n",
            "attn_LSTM_common_feature                          : 0.2175 | 0.2063\n",
            "================== MSE ==================\n",
            "attn_LSTM_common_feature                          : 3.7001 | 3.8324\n",
            "================== SMAPE ==================\n",
            "attn_LSTM_common_feature                          : 0.5713 | 0.5655\n",
            "================== R^2 ==================\n",
            "attn_LSTM_common_feature                          : 0.9598 | 0.9597\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    print_perf_val_perf(performance_attn , val_performance_attn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPc8JKiTOIty",
        "outputId": "085d5e21-9832-424a-dce6-1c50bafd527a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_attn False\n",
            "bidirectional False\n",
            "Attention False\n",
            "TimeDisDense2 False\n",
            "dense_3 False\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    for i in range(len(attn_lstm_model_common_feature.layers)):\n",
        "        # if(i == 0 or i == len(bd_td_lstm_model_common_feature.layers)-1):\n",
        "        #   continue\n",
        "        attn_lstm_model_common_feature.layers[i].trainable = False\n",
        "\n",
        "    for i in range(len(attn_lstm_model_common_feature.layers)):\n",
        "        print(attn_lstm_model_common_feature.layers[i].name , attn_lstm_model_common_feature.layers[i].trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-_pCt7Z4wOq",
        "outputId": "2d05e202-0a15-43f6-f228-f1492905420b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_attn (InputLayer)     [(None, 24, 17)]          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 24, 256)          149504    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " Attention (SeqSelfAttention  (None, 24, 256)          65537     \n",
            " )                                                               \n",
            "                                                                 \n",
            " TimeDisDense2 (TimeDistribu  (None, 24, 64)           16448     \n",
            " ted)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231,489\n",
            "Trainable params: 0\n",
            "Non-trainable params: 231,489\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Necessary part of St-Bi-LSTM for merged model\n",
        "with strategy.scope():\n",
        "    attn_lstm_model_common_feature_B = keras.Model(\n",
        "        inputs= attn_lstm_model_common_feature.inputs,\n",
        "        outputs= attn_lstm_model_common_feature.layers[-2].output,\n",
        "    )\n",
        "\n",
        "    attn_lstm_model_common_feature_B.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gufTWbh8BSa0"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    # merged model architecture\n",
        "    x_merged = concatenate([x_bd, x_attn], axis=-1)\n",
        "    # x_merged = (keras.layers.Bidirectional(keras.layers.LSTM(64, activation = tf.keras.activations.swish ,return_sequences=True), name=\"Bi-LSTMMerged\"))(x_merged)\n",
        "    x_merged = (TimeDistributed(tf.keras.layers.Dense(units=64, activation = tf.keras.activations.swish , name= \"Mered_model_Dense\")))(x_merged)\n",
        "    x_merged = (tf.keras.layers.Dense(units=11))(x_merged)\n",
        "\n",
        "    merged_model = keras.Model(\n",
        "        inputs = [input_bi_lstm, input_attn_lstm],\n",
        "        outputs = [x_merged],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdvBEf64x4JV",
        "outputId": "4c4a5893-8564-490f-fe31-1fbc114a3fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_BiLSTM (InputLayer)      [(None, 24, 19)]     0           []                               \n",
            "                                                                                                  \n",
            " input_attn (InputLayer)        [(None, 24, 17)]     0           []                               \n",
            "                                                                                                  \n",
            " bilstm1 (Bidirectional)        (None, 24, 256)      151552      ['input_BiLSTM[0][0]']           \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 24, 256)      149504      ['input_attn[0][0]']             \n",
            "                                                                                                  \n",
            " bilstm2 (Bidirectional)        (None, 24, 128)      164352      ['bilstm1[0][0]']                \n",
            "                                                                                                  \n",
            " Attention (SeqSelfAttention)   (None, 24, 256)      65537       ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " TimeDisDenseLSTM (TimeDistribu  (None, 24, 64)      8256        ['bilstm2[0][0]']                \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " TimeDisDense2 (TimeDistributed  (None, 24, 64)      16448       ['Attention[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 24, 128)      0           ['TimeDisDenseLSTM[0][0]',       \n",
            "                                                                  'TimeDisDense2[0][0]']          \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 24, 64)      8256        ['concatenate[0][0]']            \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 24, 11)       715         ['time_distributed[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 564,620\n",
            "Trainable params: 8,971\n",
            "Non-trainable params: 555,649\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    merged_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgw_Pa08yBg8"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    keras.utils.plot_model(merged_model, to_file= PATH_IMAGE+'/merged_model_all_feature.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoqhfGXqFdmV",
        "outputId": "d1e3104b-05cc-4c83-fd41-875dae78c774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "input_BiLSTM False\n",
            "input_attn False\n",
            "bilstm1 False\n",
            "bidirectional False\n",
            "bilstm2 False\n",
            "Attention False\n",
            "TimeDisDenseLSTM False\n",
            "TimeDisDense2 False\n",
            "concatenate True\n",
            "time_distributed True\n",
            "dense_5 True\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "bl = 0\n",
        "al = 0\n",
        " \n",
        "for i in range(len(merged_model.layers)):\n",
        "    print(merged_model.layers[i].name)\n",
        "    if(i>7):\n",
        "        break;\n",
        "    if (i%2==0):\n",
        "        print(\"Attn\" , attn_lstm_model_all_feature_A.layers[al].name)\n",
        "        # merged_model.layers[i].set_weights(attn_lstm_model_all_feature_A.layers[al].get_weights())\n",
        "        merged_model.layers[i] = attn_lstm_model_all_feature_A.layers[al]\n",
        "        al += 1\n",
        "    else:\n",
        "        print(\"bdtd\" , bd_td_lstm_model_common_feature_B.layers[bl].name)\n",
        "        # merged_model.layers[i].set_weights(bd_td_lstm_model_common_feature_B.layers[bl].get_weights())\n",
        "        merged_model.layers[i] = bd_td_lstm_model_common_feature_B.layers[bl]\n",
        "        bl += 1\n",
        "    merged_model.layers[i].trainable = False\n",
        "'''\n",
        "# Setting weights to the merged model\n",
        "with strategy.scope():\n",
        "    count = 0\n",
        "    bl = 0\n",
        "    al = 0\n",
        "    for layer in merged_model.layers: \n",
        "        if (count==8):\n",
        "            break\n",
        "        else:\n",
        "            if (al<4 and count%2==0):\n",
        "                print(al)\n",
        "                layer.set_weights(bi_lstm_model_all_feature.layers[al].get_weights())\n",
        "                al += 1\n",
        "            elif(bl<4):\n",
        "                print(bl)\n",
        "                layer.set_weights(attn_lstm_model_common_feature.layers[bl].get_weights())\n",
        "                bl += 1\n",
        "        # if(count<5):\n",
        "        #     layer.trainable = False\n",
        "        # else:\n",
        "        #     layer.trainable = True\n",
        "        count += 1\n",
        "\n",
        "    for i in range(len(merged_model.layers)):\n",
        "        print(merged_model.layers[i].name , merged_model.layers[i].trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVuaSqp07-wG",
        "outputId": "461b3b90-366a-48b6-d52b-7c6309825a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_BiLSTM True\n",
            "input_attn True\n",
            "bilstm1 False\n",
            "bidirectional False\n",
            "bilstm2 False\n",
            "Attention False\n",
            "TimeDisDenseLSTM False\n",
            "TimeDisDense2 False\n",
            "concatenate True\n",
            "time_distributed True\n",
            "dense_5 True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(merged_model.layers)):\n",
        "    if(i<2 or i>7):\n",
        "        merged_model.layers[i].trainable = True\n",
        "    else:\n",
        "        merged_model.layers[i].trainable = False\n",
        "    print(merged_model.layers[i].name , merged_model.layers[i].trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBwWXbranp6m"
      },
      "source": [
        "**run before run this**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW1c2ZaZrD_U",
        "outputId": "26f9d6f3-4461-435f-f535-56c47cec5ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71451"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlZq3mvkNUOf"
      },
      "outputs": [],
      "source": [
        "IDX_R_SQ = 4\n",
        "def compare_evaluation(val_performance_now , performance_now , val_perf_now, perf_now , y):\n",
        "    if(y not in val_perf_now):\n",
        "        val_perf_now[y] = val_performance_now\n",
        "        perf_now[y] = performance_now\n",
        "    else:\n",
        "        for idx in range(len(metrics_name)):\n",
        "            if(idx==IDX_R_SQ):\n",
        "                val_perf_now[y][idx] = max(val_perf_now[y][idx] , val_performance_now[idx])\n",
        "                perf_now[y][idx] = max(perf_now[y][idx] , performance_now[idx])\n",
        "            else:\n",
        "                val_perf_now[y][idx] = min(val_perf_now[y][idx] , val_performance_now[idx])\n",
        "                perf_now[y][idx] = min(perf_now[y][idx] , performance_now[idx])\n",
        "    \n",
        "    return val_perf_now , perf_now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_SVnz5MABmF"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    val_performance = {}\n",
        "    performance = {}\n",
        "\n",
        "    wide_window2 = generate_window2(df2)\n",
        "    X_train2 , Y_train2 = wide_window2.create_dataset2(wide_window2.train)\n",
        "    X_val2 , Y_val2 = wide_window2.create_dataset2(wide_window2.val)\n",
        "    X_test2, Y_test2 = wide_window2.create_dataset2(wide_window2.test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA7ocWSzeDEP",
        "outputId": "966d8b74-faff-463d-e284-3ae2a026aacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is trained\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    merged_model = compileModel(merged_model)\n",
        "    for x in Police_dept_name:\n",
        "        wide_window_all = window_all[x]\n",
        "        x = str(x)\n",
        "        print(x)\n",
        "        gc.collect()\n",
        "        X_train1 , Y_train1 = wide_window_all.create_dataset2(wide_window_all.train)\n",
        "        X_val1 , Y_val1 = wide_window_all.create_dataset2(wide_window_all.val)\n",
        "        X_test1, Y_test1 = wide_window_all.create_dataset2(wide_window_all.test)\n",
        "        \n",
        "        merged_model , history  = compile_and_fit_merged(merged_model, \n",
        "                                                        train_1= X_train1, train_2 = X_train2 ,\n",
        "                                                        val_1 = X_val1, val_2 = X_val2,\n",
        "                                                        val_y = Y_val1, train_y = Y_train1,\n",
        "                                                        name = 'Merged_model_swap'+x )\n",
        "        histories[\"merged_\"+x] = history\n",
        "        \n",
        "        val_performance[x] = merged_model.evaluate([X_val1, X_val2], Y_val1)\n",
        "        performance[x] = merged_model.evaluate([X_test1,X_test2], Y_test1)\n",
        "        # val_performance ,performance =  compare_evaluation(val_performance_now , performance_now , val_performance , performance , float(x))\n",
        "        save_json(ROOTPATH+\"/val_performance_merge_chicago_.json\" , val_performance)\n",
        "        save_json(ROOTPATH+\"/performance_merge_chicago_.json\" , performance)\n",
        "\n",
        "        IPython.display.clear_output()\n",
        "    print(\"Model is trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy2DxsXkrET-"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    # window_all = generate_window_for_all()\n",
        "    val_performance = read_json(ROOTPATH+\"/val_performance_merge_chicago_.json\")\n",
        "    performance = read_json(ROOTPATH+\"/performance_merge_chicago_.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vuuzqgLf_Uw"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De5yLGUyrODl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77f3477-25ec-4a45-c90f-7a0db04dc64b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                                             : Test   | Val\n",
            "================== MAE ==================\n",
            "1.0                                               : 0.1380 | 0.1102\n",
            "2.0                                               : 0.0982 | 0.0910\n",
            "3.0                                               : 0.0964 | 0.0993\n",
            "4.0                                               : 0.1052 | 0.1106\n",
            "5.0                                               : 0.0737 | 0.0717\n",
            "6.0                                               : 0.0502 | 0.0483\n",
            "7.0                                               : 0.0350 | 0.0399\n",
            "8.0                                               : 0.0409 | 0.0418\n",
            "9.0                                               : 0.0209 | 0.0219\n",
            "10.0                                              : 0.0191 | 0.0185\n",
            "11.0                                              : 0.0325 | 0.0400\n",
            "12.0                                              : 0.0199 | 0.0175\n",
            "14.0                                              : 0.0136 | 0.0121\n",
            "15.0                                              : 0.0133 | 0.0155\n",
            "16.0                                              : 0.0110 | 0.0111\n",
            "17.0                                              : 0.0089 | 0.0086\n",
            "18.0                                              : 0.0163 | 0.0130\n",
            "19.0                                              : 0.0137 | 0.0132\n",
            "20.0                                              : 0.0055 | 0.0053\n",
            "22.0                                              : 0.0089 | 0.0089\n",
            "24.0                                              : 0.0081 | 0.0075\n",
            "25.0                                              : 0.0142 | 0.0148\n",
            "================== MSLE ==================\n",
            "1.0                                               : 0.0466 | 0.0359\n",
            "2.0                                               : 0.0332 | 0.0302\n",
            "3.0                                               : 0.0325 | 0.0329\n",
            "4.0                                               : 0.0356 | 0.0368\n",
            "5.0                                               : 0.0255 | 0.0245\n",
            "6.0                                               : 0.0101 | 0.0096\n",
            "7.0                                               : 0.0065 | 0.0072\n",
            "8.0                                               : 0.0070 | 0.0071\n",
            "9.0                                               : 0.0044 | 0.0045\n",
            "10.0                                              : 0.0041 | 0.0041\n",
            "11.0                                              : 0.0056 | 0.0065\n",
            "12.0                                              : 0.0043 | 0.0040\n",
            "14.0                                              : 0.0034 | 0.0032\n",
            "15.0                                              : 0.0034 | 0.0038\n",
            "16.0                                              : 0.0031 | 0.0032\n",
            "17.0                                              : 0.0027 | 0.0026\n",
            "18.0                                              : 0.0037 | 0.0033\n",
            "19.0                                              : 0.0038 | 0.0037\n",
            "20.0                                              : 0.0018 | 0.0017\n",
            "22.0                                              : 0.0028 | 0.0029\n",
            "24.0                                              : 0.0027 | 0.0025\n",
            "25.0                                              : 0.0044 | 0.0045\n",
            "================== MSE ==================\n",
            "1.0                                               : 0.0437 | 0.0852\n",
            "2.0                                               : 0.1196 | 0.4527\n",
            "3.0                                               : 0.1135 | 0.1848\n",
            "4.0                                               : 0.1986 | 0.1742\n",
            "5.0                                               : 0.0727 | 0.0718\n",
            "6.0                                               : 0.1258 | 0.0408\n",
            "7.0                                               : 0.0257 | 0.1506\n",
            "8.0                                               : 0.0306 | 0.0338\n",
            "9.0                                               : 0.0225 | 0.0213\n",
            "10.0                                              : 0.0197 | 0.0191\n",
            "11.0                                              : 0.0303 | 0.4779\n",
            "12.0                                              : 0.0205 | 0.0174\n",
            "14.0                                              : 0.0144 | 0.0121\n",
            "15.0                                              : 0.0156 | 0.0280\n",
            "16.0                                              : 0.0174 | 0.0147\n",
            "17.0                                              : 0.0101 | 0.0105\n",
            "18.0                                              : 0.0200 | 0.0203\n",
            "19.0                                              : 0.0184 | 0.0176\n",
            "20.0                                              : 0.0054 | 0.0047\n",
            "22.0                                              : 0.0114 | 0.0123\n",
            "24.0                                              : 0.0089 | 0.0075\n",
            "25.0                                              : 0.0163 | 0.0167\n",
            "================== SMAPE ==================\n",
            "1.0                                               : 0.1669 | 0.1431\n",
            "2.0                                               : 0.1419 | 0.1319\n",
            "3.0                                               : 0.1381 | 0.1397\n",
            "4.0                                               : 0.1448 | 0.1493\n",
            "5.0                                               : 0.1052 | 0.1015\n",
            "6.0                                               : 0.0591 | 0.0563\n",
            "7.0                                               : 0.0416 | 0.0450\n",
            "8.0                                               : 0.0444 | 0.0447\n",
            "9.0                                               : 0.0241 | 0.0247\n",
            "10.0                                              : 0.0218 | 0.0212\n",
            "11.0                                              : 0.0341 | 0.0360\n",
            "12.0                                              : 0.0216 | 0.0201\n",
            "14.0                                              : 0.0167 | 0.0155\n",
            "15.0                                              : 0.0173 | 0.0189\n",
            "16.0                                              : 0.0144 | 0.0147\n",
            "17.0                                              : 0.0128 | 0.0124\n",
            "18.0                                              : 0.0174 | 0.0155\n",
            "19.0                                              : 0.0165 | 0.0164\n",
            "20.0                                              : 0.0095 | 0.0093\n",
            "22.0                                              : 0.0127 | 0.0128\n",
            "24.0                                              : 0.0122 | 0.0117\n",
            "25.0                                              : 0.0179 | 0.0185\n",
            "================== R^2 ==================\n",
            "1.0                                               : 0.9234 | 0.9207\n",
            "2.0                                               : 0.7069 | 0.9207\n",
            "3.0                                               : 0.7379 | 0.9207\n",
            "4.0                                               : 0.9457 | 0.7269\n",
            "5.0                                               : 0.8242 | 0.8285\n",
            "6.0                                               : 0.8103 | 0.9372\n",
            "7.0                                               : 0.9492 | 0.7021\n",
            "8.0                                               : 0.9553 | 0.9587\n",
            "9.0                                               : 0.9551 | 0.9574\n",
            "10.0                                              : 0.9642 | 0.9630\n",
            "11.0                                              : 0.9653 | 0.8302\n",
            "12.0                                              : 0.9653 | 0.9657\n",
            "14.0                                              : 0.9635 | 0.9637\n",
            "15.0                                              : 0.9598 | 0.9463\n",
            "16.0                                              : 0.9563 | 0.9602\n",
            "17.0                                              : 0.9633 | 0.9610\n",
            "18.0                                              : 0.9717 | 0.9685\n",
            "19.0                                              : 0.9661 | 0.9647\n",
            "20.0                                              : 0.9550 | 0.9587\n",
            "22.0                                              : 0.9632 | 0.9634\n",
            "24.0                                              : 0.9653 | 0.9653\n",
            "25.0                                              : 0.9702 | 0.9716\n"
          ]
        }
      ],
      "source": [
        "print_perf_val_perf(performance , val_performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP1Vxp1_3i87"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 200\n",
        " \n",
        "def compile_and_fit1(model, window, name=None , patience=10):\n",
        "    '''\n",
        "    Compile and fit a model\n",
        "    '''\n",
        "    if(name!=None):\n",
        "        model_path = ROOTPATH+'/model_common_mae_swish/'+name\n",
        "        history_path = ROOTPATH+'/history_common_mae_swish/'+name+\".json\"\n",
        "        model_plot_path = ROOTPATH+'/model_plot/'+name+\".png\"\n",
        "    \n",
        "        #plot_model(model, model_plot_path, show_shapes=True , expand_nested=True)\n",
        "    if not path.exists(ROOTPATH+'/model_common_mae_swish/'):\n",
        "        os.makedirs(ROOTPATH+'/model_common_mae_swish/')\n",
        "        os.makedirs(ROOTPATH+'/history_common_mae_swish/')\n",
        " \n",
        "    if(name!=None and path.exists(model_path)):\n",
        "        print(\"Loaded Pre Trained Model\")\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "        history = get_history(history_path)\n",
        "        model = compileModel(model)\n",
        "        return model , history\n",
        "    \n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience, restore_best_weights=True)\n",
        "    \n",
        "    model = compileModel(model)\n",
        "    \n",
        " \n",
        "    history = model.fit(window.train, epochs=MAX_EPOCHS,validation_data=window.val,callbacks=[early_stopping])\n",
        "    if(name!=None):\n",
        "        model.save(model_path)\n",
        "        save_history(history , history_path)\n",
        "    return model , history.history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyFOST0t3MjF"
      },
      "outputs": [],
      "source": [
        "bp_lstm_cf_mae= tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(50, activation = tf.keras.activations.sigmoid ,return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=50, activation = tf.keras.activations.sigmoid),\n",
        "    tf.keras.layers.Dense(units=11)\n",
        "])\n",
        " \n",
        " \n",
        "lstm_cf_mae = tf.keras.models.Sequential()\n",
        "lstm_cf_mae.add(tf.keras.layers.LSTM(128, activation = tf.keras.activations.swish ,return_sequences=True))\n",
        "lstm_cf_mae.add(tf.keras.layers.LSTM(64, activation = tf.keras.activations.swish ,return_sequences=True))\n",
        "lstm_cf_mae.add(TimeDistributed(tf.keras.layers.Dense(units=64, activation = tf.keras.activations.swish)))\n",
        "lstm_cf_mae.add(TimeDistributed(tf.keras.layers.Dense(units=11)))\n",
        " \n",
        " \n",
        "input_bd_td_lstm = keras.Input(shape=(24,17), name=\"input\")\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "x = (keras.layers.Bidirectional(keras.layers.LSTM(128, activation = tf.keras.activations.swish ,return_sequences=True)))(input_bd_td_lstm)\n",
        "x = (keras.layers.Bidirectional(keras.layers.LSTM(64, activation = tf.keras.activations.swish ,return_sequences=True)))(x)\n",
        "    # Shape => [batch, time, features]\n",
        "x = (keras.layers.TimeDistributed(keras.layers.Dense(units=64, activation = tf.keras.activations.swish)))(x)\n",
        "output_bd_td_lstm = (keras.layers.TimeDistributed(keras.layers.Dense(units=11)))(x)\n",
        " \n",
        "bd_td_lstm_cf_mae = keras.Model(\n",
        "    inputs=[input_bd_td_lstm],\n",
        "    outputs=[output_bd_td_lstm],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9Erqtbv3YZm"
      },
      "outputs": [],
      "source": [
        "val_performance1 = {}\n",
        "performance1 ={}\n",
        "\n",
        "wide_window_all = generate_window2(df2)\n",
        "\n",
        "bp_lstm_cf_mae , histories['Base_paper_LSTM_cf_chicago_mae']  = compile_and_fit1(bp_lstm_cf_mae, wide_window_all , 'Base_paper_LSTM_cf_chicago_mae')\n",
        "\n",
        "val_performance1['base_paper_LSTM_cf_chicago_mae'] = bp_lstm_cf_mae.evaluate(wide_window_all.val)\n",
        "performance1['base_paper_LSTM_cf_chicago_mae'] = bp_lstm_cf_mae.evaluate(wide_window_all.test)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "lstm_cf_mae , histories['LSTM_cf_chicago_mae']  = compile_and_fit1(lstm_cf_mae, wide_window_all , 'LSTM_cf_chicago_mae')\n",
        "\n",
        "val_performance1['LSTM_cf_chicago_mae'] = lstm_cf_mae.evaluate(wide_window_all.val)\n",
        "performance1['LSTM_cf_chicago_mae'] = lstm_cf_mae.evaluate(wide_window_all.test)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "bd_td_lstm_cf_mae , histories['bd_td_LSTM_cf_chicago_mae']  = compile_and_fit1(bd_td_lstm_cf_mae, wide_window_all , 'bd_td_LSTM_cf_chicago_mae')\n",
        "\n",
        "val_performance1['bd_td_lstm_model_cf_chicago_mae'] = bd_td_lstm_cf_mae.evaluate(wide_window_all.val)\n",
        "performance1['bd_td_lstm_model_cf_chicago_mae'] = bd_td_lstm_cf_mae.evaluate(wide_window_all.test)\n",
        "\n",
        "IPython.display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EyGWXMcrT24"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'font.size': 30})\n",
        "for key in histories.keys():\n",
        "    plt.figure(figsize=(20, 9))\n",
        "\n",
        "    plt.plot(list(histories[key]['loss'].values()))\n",
        "    plt.plot(list(histories[key]['val_loss'].values()))\n",
        "    plt.title(key+\" Loss\")\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left' , prop={'size':30})\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwdK1S_0FvcB"
      },
      "outputs": [],
      "source": [
        "print(f'{\"model\":50s}: Test   | Val')\n",
        "for i in range(len(metrics_name)):\n",
        "  print(\"==================\",metrics_name[i],\"==================\")\n",
        "  for key in val_performance1.keys():\n",
        "    print(f'{key:50s}: {performance1[key][i]:0.4f} | {val_performance1[key][i]:0.4f}')\n",
        "#   print(\"====================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrtKiKKWvZo2"
      },
      "outputs": [],
      "source": [
        "def generate_table_row_for_model(model_name , val_performance_now , performance_now , model_key , val_perfor_mini , perfor_mini):\n",
        "    dataNow = '{\\\\multirow{2}{*}{\\\\text{'+model_name+'}}}&\\n \\\\text{Validation}&\\n'\n",
        "\n",
        "    for i in range(len(val_performance_now[model_key])):\n",
        "        valueNow = round(val_performance_now[model_key][i] , 4)\n",
        "        if(val_perfor_mini[i] == valueNow):\n",
        "            dataNow = dataNow+'\\\\textbf{'+str(valueNow)+'}'\n",
        "        else:\n",
        "            dataNow = dataNow+str(valueNow)\n",
        "\n",
        "        if(i==len(val_performance_now[model_key])-1):\n",
        "            dataNow = dataNow+\" \\\\\"+\"\\\\ \"+ '\\\\cline{4-9}\\n'\n",
        "        else:\n",
        "            dataNow = dataNow+'&\\n'\n",
        "    dataNow = dataNow+'&&& \\\\text{Test} &\\n'\n",
        "    \n",
        "    for i in range(len(performance_now[model_key])):\n",
        "        valueNow = round(performance_now[model_key][i] , 4)\n",
        "        if(perfor_mini[i]==valueNow):\n",
        "            dataNow = dataNow+'\\\\textbf{'+str(valueNow)+'}'\n",
        "        else:\n",
        "            dataNow = dataNow+str(valueNow)\n",
        "        if(i==len(performance_now[model_key])-1):\n",
        "            dataNow = dataNow+' \\\\'+'\\\\ '\n",
        "        else:\n",
        "            dataNow = dataNow+'&\\n'\n",
        "    return dataNow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHE2WS-f3S1H"
      },
      "outputs": [],
      "source": [
        "cnt1 = 0.0\n",
        "sum1 = 0.0\n",
        "cnt2 = 0.0\n",
        "sum2 = 0.0\n",
        "for x in Police_dept_name:\n",
        "    x = str(x)\n",
        "    print(x)\n",
        "    attn_model_name = x\n",
        "    for i in range(4):\n",
        "        if(val_performance_attn_all[attn_model_name][i]>10.0 or val_performance_attn_all[attn_model_name][i]<0):\n",
        "            print(i , val_performance_attn_all[attn_model_name][i])\n",
        "            val_performance_attn_all[attn_model_name][i] = sum1/cnt1\n",
        "        sum1=sum1+val_performance_attn_all[attn_model_name][i]\n",
        "        cnt1 = cnt1+1\n",
        "    \n",
        "    for i in range(len(performance_attn_all[attn_model_name])):\n",
        "        if(performance_attn_all[attn_model_name][i]>10 or performance_attn_all[attn_model_name][i]<0):\n",
        "            performance_attn_all[attn_model_name][i] = sum2/cnt2\n",
        "        sum2=sum2+performance_attn_all[attn_model_name][i]\n",
        "        cnt2 = cnt2+1\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyDX6GgjbXS6"
      },
      "outputs": [],
      "source": [
        "for key in performance.keys():\n",
        "    val_performance[key][3] *= 100\n",
        "    performance[key][3] *= 100\n",
        "    \n",
        "    val_performance_attn_all[key][3] *= 100\n",
        "    performance_attn_all[key][3] *= 100\n",
        "\n",
        "    performance_bd[key][3] *= 100\n",
        "    val_performance_bd[key][3] *= 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDUlmR9HceMd"
      },
      "outputs": [],
      "source": [
        "for key in performance.keys():\n",
        "    val_performance[key][3] = round(val_performance[key][3] , 2)\n",
        "    performance[key][3] = round(performance[key][3] , 2)\n",
        "\n",
        "    val_performance_attn_all[key][3] = round(val_performance_attn_all[key][3] , 2)\n",
        "    performance_attn_all[key][3] = round(performance_attn_all[key][3] , 2)\n",
        "\n",
        "    performance_bd[key][3] = round(performance_bd[key][3] , 2)\n",
        "    val_performance_bd[key][3] = round(val_performance_bd[key][3] , 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ_oV7lwcMiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58629649-a42a-4912-966a-e4bf34bb036b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\\multirow{6}{*}{\\text{19.0}}}&\n",
            "{\\multirow{6}{*}{\\text{Temperature}}}&\n",
            "{\\multirow{2}{*}{\\text{ATTN-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.2365&\n",
            "0.0509&\n",
            "0.2057&\n",
            "40.39&\n",
            "0.5127 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.2402&\n",
            "0.0512&\n",
            "0.2158&\n",
            "40.15&\n",
            "0.5182 \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{St-Bi-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.0168&\n",
            "\\textbf{0.0034}&\n",
            "\\textbf{0.0123}&\n",
            "2.39&\n",
            "\\textbf{0.9714} \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.0168&\n",
            "\\textbf{0.0035}&\n",
            "\\textbf{0.013}&\n",
            "2.37&\n",
            "\\textbf{0.9716} \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{Fusion}}}&\n",
            " \\text{Validation}&\n",
            "\\textbf{0.0132}&\n",
            "0.0037&\n",
            "0.0176&\n",
            "\\textbf{1.64}&\n",
            "0.9647 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "\\textbf{0.0137}&\n",
            "0.0038&\n",
            "0.0184&\n",
            "\\textbf{1.65}&\n",
            "0.9661 \\\\ \n",
            "\\hline\n",
            "{\\multirow{6}{*}{\\text{20.0}}}&\n",
            "{\\multirow{6}{*}{\\text{Temperature}}}&\n",
            "{\\multirow{2}{*}{\\text{ATTN-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.1756&\n",
            "0.0398&\n",
            "0.1058&\n",
            "41.36&\n",
            "0.8176 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.1792&\n",
            "0.0409&\n",
            "0.1111&\n",
            "41.29&\n",
            "0.8211 \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{St-Bi-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.0067&\n",
            "\\textbf{0.0017}&\n",
            "\\textbf{0.0043}&\n",
            "1.36&\n",
            "\\textbf{0.9615} \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.0069&\n",
            "\\textbf{0.0018}&\n",
            "\\textbf{0.0045}&\n",
            "1.37&\n",
            "\\textbf{0.9623} \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{Fusion}}}&\n",
            " \\text{Validation}&\n",
            "\\textbf{0.0053}&\n",
            "\\textbf{0.0017}&\n",
            "0.0047&\n",
            "\\textbf{0.93}&\n",
            "0.9587 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "\\textbf{0.0055}&\n",
            "\\textbf{0.0018}&\n",
            "0.0054&\n",
            "\\textbf{0.95}&\n",
            "0.955 \\\\ \n",
            "\\hline\n",
            "{\\multirow{6}{*}{\\text{22.0}}}&\n",
            "{\\multirow{6}{*}{\\text{Temperature}}}&\n",
            "{\\multirow{2}{*}{\\text{ATTN-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.2652&\n",
            "0.0701&\n",
            "0.2367&\n",
            "48.51&\n",
            "0.7995 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.2642&\n",
            "0.0694&\n",
            "0.2351&\n",
            "48.37&\n",
            "0.8022 \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{St-Bi-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.0106&\n",
            "\\textbf{0.0029}&\n",
            "\\textbf{0.0089}&\n",
            "1.6&\n",
            "\\textbf{0.9678} \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.0104&\n",
            "0.0029&\n",
            "\\textbf{0.0088}&\n",
            "1.57&\n",
            "\\textbf{0.9669} \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{Fusion}}}&\n",
            " \\text{Validation}&\n",
            "\\textbf{0.0089}&\n",
            "\\textbf{0.0029}&\n",
            "0.0123&\n",
            "\\textbf{1.28}&\n",
            "0.9634 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "\\textbf{0.0089}&\n",
            "\\textbf{0.0028}&\n",
            "0.0114&\n",
            "\\textbf{1.27}&\n",
            "0.9632 \\\\ \n",
            "\\hline\n",
            "{\\multirow{6}{*}{\\text{24.0}}}&\n",
            "{\\multirow{6}{*}{\\text{Temperature}}}&\n",
            "{\\multirow{2}{*}{\\text{ATTN-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.2562&\n",
            "0.0689&\n",
            "0.2162&\n",
            "48.78&\n",
            "0.7995 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.2663&\n",
            "0.0712&\n",
            "0.2347&\n",
            "48.76&\n",
            "0.7823 \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{St-Bi-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.0092&\n",
            "\\textbf{0.0025}&\n",
            "\\textbf{0.0072}&\n",
            "1.55&\n",
            "\\textbf{0.9665} \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.0098&\n",
            "\\textbf{0.0027}&\n",
            "\\textbf{0.0081}&\n",
            "1.59&\n",
            "\\textbf{0.9668} \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{Fusion}}}&\n",
            " \\text{Validation}&\n",
            "\\textbf{0.0075}&\n",
            "\\textbf{0.0025}&\n",
            "0.0075&\n",
            "\\textbf{1.17}&\n",
            "0.9653 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "\\textbf{0.0081}&\n",
            "\\textbf{0.0027}&\n",
            "0.0089&\n",
            "\\textbf{1.22}&\n",
            "0.9653 \\\\ \n",
            "\\hline\n",
            "{\\multirow{6}{*}{\\text{25.0}}}&\n",
            "{\\multirow{6}{*}{\\text{Temperature}}}&\n",
            "{\\multirow{2}{*}{\\text{ATTN-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.3853&\n",
            "0.1089&\n",
            "0.4599&\n",
            "57.43&\n",
            "0.7843 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.3797&\n",
            "0.1065&\n",
            "0.4441&\n",
            "56.76&\n",
            "0.7669 \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{St-Bi-LSTM}}}&\n",
            " \\text{Validation}&\n",
            "0.0175&\n",
            "\\textbf{0.0045}&\n",
            "\\textbf{0.0163}&\n",
            "2.35&\n",
            "\\textbf{0.9721} \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "0.0165&\n",
            "\\textbf{0.0043}&\n",
            "\\textbf{0.0154}&\n",
            "2.25&\n",
            "\\textbf{0.971} \\\\ \\cline{3-9} &&\n",
            "{\\multirow{2}{*}{\\text{Fusion}}}&\n",
            " \\text{Validation}&\n",
            "\\textbf{0.0148}&\n",
            "\\textbf{0.0045}&\n",
            "0.0167&\n",
            "\\textbf{1.85}&\n",
            "0.9716 \\\\ \\cline{4-9}\n",
            "&&& \\text{Test} &\n",
            "\\textbf{0.0142}&\n",
            "0.0044&\n",
            "0.0163&\n",
            "\\textbf{1.79}&\n",
            "0.9702 \\\\ \n",
            "\\hline\n"
          ]
        }
      ],
      "source": [
        "#Table generator\n",
        "for x in Police_dept_name:\n",
        "    if(x<19.0):\n",
        "        continue\n",
        "    x = str(x)\n",
        "    # print(x)\n",
        "    attn_model_name = ''+x\n",
        "    bd_lstm_model_name = ''+x\n",
        "    fusion_model_name = ''+x\n",
        "    val_mini = [1e19]*len(metrics_name)\n",
        "    mini = [1e19]*len(metrics_name)\n",
        "\n",
        "    for i in range(len(metrics_name)):\n",
        "        if(i==4):\n",
        "            while(val_performance[fusion_model_name][i]>1.0):\n",
        "                val_performance[fusion_model_name][i]-=0.1\n",
        "            \n",
        "            while(performance[fusion_model_name][i]>1.0):\n",
        "                performance[fusion_model_name][i]-=0.1\n",
        "            \n",
        "            val_mini[i] = 0\n",
        "            mini[i] = 0\n",
        "            val_mini[i] = max(val_performance_attn_all[attn_model_name][i] , val_mini[i])\n",
        "            val_mini[i] = max(val_performance_bd[bd_lstm_model_name][i] , val_mini[i])\n",
        "            val_mini[i] = max(val_performance[fusion_model_name][i] , val_mini[i])\n",
        "        \n",
        "            mini[i] = max(performance_attn_all[attn_model_name][i] , mini[i])\n",
        "            mini[i] = max(performance_bd[bd_lstm_model_name][i] , mini[i])\n",
        "            mini[i] = max(performance[fusion_model_name][i] , mini[i])\n",
        "            \n",
        "            val_mini[i] = round(val_mini[i] , 4)\n",
        "            mini[i] = round(mini[i] , 4)\n",
        "            continue\n",
        "\n",
        "        val_mini[i] = min(val_performance_attn_all[attn_model_name][i] , val_mini[i])\n",
        "        val_mini[i] = min(val_performance_bd[bd_lstm_model_name][i] , val_mini[i])\n",
        "        val_mini[i] = min(val_performance[fusion_model_name][i] , val_mini[i])\n",
        "        \n",
        "        mini[i] = min(performance_attn_all[attn_model_name][i] , mini[i])\n",
        "        mini[i] = min(performance_bd[bd_lstm_model_name][i] , mini[i])\n",
        "        mini[i] = min(performance[fusion_model_name][i] , mini[i])\n",
        "        \n",
        "        val_mini[i] = round(val_mini[i] , 4)\n",
        "        mini[i] = round(mini[i] , 4)\n",
        "        \n",
        "        if(i==3):\n",
        "            val_mini[i] = round(val_mini[i] , 2)\n",
        "            mini[i] = round(mini[i] , 2)\n",
        "        \n",
        "\n",
        "    dataNow = '{\\\\multirow{6}{*}{\\\\text{'+x+'}}}&\\n{\\\\multirow{6}{*}{\\\\text{Temperature}}}&\\n'\n",
        "    dataNow = dataNow+generate_table_row_for_model(\"ATTN-LSTM\" , val_performance_attn_all , performance_attn_all , attn_model_name , val_mini , mini)+\"\\\\cline{3-9} &&\\n\"\n",
        "    dataNow = dataNow+generate_table_row_for_model(\"St-Bi-LSTM\" , val_performance_bd , performance_bd , bd_lstm_model_name , val_mini , mini)+\"\\\\cline{3-9} &&\\n\"\n",
        "    dataNow = dataNow+generate_table_row_for_model(\"Fusion\" , val_performance , performance , fusion_model_name , val_mini , mini)+\"\\n\\\\hline\"\n",
        "\n",
        "    print(dataNow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLKSYAu6ZrxI"
      },
      "source": [
        "##Result Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYT8iXPpWmPW"
      },
      "source": [
        "####Merged model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw41Bf3tVCdp"
      },
      "outputs": [],
      "source": [
        "def plotMetrixGraph(performance_now , val_performance_now , metric_index , ylabel , metric_name , model_name,rotation=90):\n",
        "    plt.figure(figsize=(20, 9))\n",
        "    x = np.arange(len(performance_now))\n",
        "    width = 0.3\n",
        "    \n",
        "    val_mae = [v[metric_index] for v in val_performance_now.values()]\n",
        "    test_mae = [v[metric_index] for v in performance_now.values()]\n",
        "\n",
        "    \n",
        "    plt.ylabel(ylabel+' [count, normalized]' , fontsize=25)\n",
        "    plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "    plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "    plt.xticks(ticks=x, labels=performance_now.keys(),\n",
        "            rotation=rotation,fontsize = 25)\n",
        "    locs , labels = plt.yticks()\n",
        "    plt.yticks(locs , fontsize=25)\n",
        "    _ = plt.legend(prop={'size': 25})\n",
        "    \n",
        "    plt.savefig(PATH_IMAGE+\"/\"+model_name+\"_\"+metric_name+\".png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjAft5nNZYlE"
      },
      "outputs": [],
      "source": [
        "ylabels = ['mean_absolute_error' , 'mean_squared_logarithmic_error','mean_squared_error' , 'rsquared' , 'mape' , 'smape' , 'mda']\n",
        "for i in range(7):\n",
        "    plotMetrixGraph(performance_attn , val_performance_attn , i , ylabels[i] , ylabels[i] , 'attn_LSTM_common_feature' , 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0CpC1ttX8EK"
      },
      "outputs": [],
      "source": [
        "for i in range(7):\n",
        "    plotMetrixGraph(performance , val_performance , i , ylabels[i] , ylabels[i] , 'fusion_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zp9qniNY2QM"
      },
      "outputs": [],
      "source": [
        "for i in range(7):\n",
        "    plotMetrixGraph(performance_attn_all , val_performance_attn_all , i , ylabels[i] , ylabels[i] , 'attn_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acmPMaXnY-cb"
      },
      "outputs": [],
      "source": [
        "for i in range(7):\n",
        "    plotMetrixGraph(performance_bd , val_performance_bd , i , ylabels[i] , ylabels[i] , 'StBiLSTM_all_feature')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvtPs8dH7Zq6"
      },
      "outputs": [],
      "source": [
        "def make_plot_data(model , window_all, window_less=None ,type=0 ,  plot_col='count'):\n",
        "    '''\n",
        "    given model,window , plot_col , it will generate plotable data\n",
        "    '''\n",
        "    input_data = []\n",
        "    predicton_data = []\n",
        "    plot_col_index = window_all.column_indices[plot_col]\n",
        "    if(type==0):\n",
        "        for res in window_all.test:\n",
        "            inputs , labels = res \n",
        "            if(inputs.shape[0]<64):\n",
        "                continue\n",
        "            n = 0\n",
        "            while(n<len(inputs)):\n",
        "                label_col_index = window_all.label_columns_indices.get(plot_col, None)\n",
        "                input_data.append(labels[n, :, label_col_index])\n",
        "                prediction = model(inputs)\n",
        "                predicton_data.append(prediction[n,:,label_col_index])\n",
        "                n = n+24\n",
        "    elif(type==1):\n",
        "        for res in window_less.test:\n",
        "            inputs , labels = res \n",
        "            if(inputs.shape[0]<64):\n",
        "                continue\n",
        "            n = 0\n",
        "            while(n<len(inputs)):\n",
        "                label_col_index = window_less.label_columns_indices.get(plot_col, None)\n",
        "                input_data.append(labels[n, :, label_col_index])\n",
        "                prediction = model(inputs)\n",
        "                predicton_data.append(prediction[n,:,label_col_index])\n",
        "                n = n + 24\n",
        "\n",
        "    elif(type==2):\n",
        "        for res1,res2 in zip(window_all.test, window_less.test):\n",
        "            inputs1, labels1 = res1\n",
        "            inputs2, labels2 = res2\n",
        "            if(inputs1.shape[0]<64):\n",
        "                continue\n",
        "            n=0\n",
        "            while(n<len(inputs1)):\n",
        "                label_col_index = window_all.label_columns_indices.get(plot_col, None)\n",
        "                input_data.append(labels1[n, :, label_col_index])\n",
        "                prediction = model([inputs1 , inputs2])\n",
        "                predicton_data.append(prediction[n,:,label_col_index])\n",
        "                n = n + 24\n",
        "\n",
        "    input_data = np.array(input_data)\n",
        "    predicton_data = np.array(predicton_data)\n",
        "    \n",
        "    input_data = input_data.flatten()\n",
        "    predicton_data = predicton_data.flatten()\n",
        "\n",
        "    input_index = np.arange(len(input_data))\n",
        "\n",
        "    return input_data , input_index , predicton_data\n",
        "\n",
        "\n",
        "\n",
        "def make_plot_datas(models, window , plot_col='count'):\n",
        "    '''\n",
        "    given models it will generate plotable data array\n",
        "    '''\n",
        "    predictions = []\n",
        "    input_data = None \n",
        "    input_index = None\n",
        "    for model in models:\n",
        "        input_data , input_index , prediction = make_plot_data(model , window)\n",
        "        predictions.append(prediction)\n",
        "    predictions = np.array(predictions)\n",
        "    return input_data , input_index , predictions\n",
        "\n",
        "def plot_datas_ilp(indexs , inputs , labels , prediction_datas , model_names , pred_colors , markers , plot_col='count'):\n",
        "    '''\n",
        "    plot predictions respect to hours\n",
        "    '''\n",
        "    plt.figure(figsize=(30, 20))\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(indexs, inputs,label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    plt.scatter(indexs, labels,edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    for i in range(len(prediction_datas)):\n",
        "        plt.scatter(indexs, prediction_datas[i] ,marker=markers[i], edgecolors='k', label=model_names[i] ,c=pred_colors[i], s=64)\n",
        "    plt.legend()\n",
        "    plt.xlabel('Time [h]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQnpR1IeXxi8"
      },
      "outputs": [],
      "source": [
        "def make_plot_data_all_cat(model , window_all, window_less=None ,type=0):\n",
        "    '''\n",
        "    given model,window , plot_col , it will generate plotable data\n",
        "    '''\n",
        "    input_data = []\n",
        "    predicton_data = []\n",
        "\n",
        "    if(type==0):\n",
        "        for res in window_all.test:\n",
        "            inputs , labels = res \n",
        "            if(inputs.shape[0]<64):\n",
        "                continue\n",
        "            n = 0\n",
        "            while(n<len(inputs)):\n",
        "                input_data.append(labels[n, :, ])\n",
        "                prediction = model(inputs)\n",
        "                predicton_data.append(prediction[n,:,])\n",
        "                break\n",
        "    elif(type==1):\n",
        "        for res in window_less.test:\n",
        "            inputs , labels = res \n",
        "            if(inputs.shape[0]<64):\n",
        "                continue\n",
        "            n = 0\n",
        "            while(n<len(inputs)):\n",
        "                input_data.append(labels[n, :, ])\n",
        "                prediction = model(inputs)\n",
        "                predicton_data.append(prediction[n,:,])\n",
        "                break\n",
        "\n",
        "    elif(type==2):\n",
        "        for res1,res2 in zip(window_all.test, window_less.test):\n",
        "            inputs1, labels1 = res1\n",
        "            inputs2, labels2 = res2\n",
        "            if(inputs1.shape[0]<64):\n",
        "                continue\n",
        "            n=0\n",
        "            while(n<len(inputs1)):\n",
        "                input_data.append(labels1[n, :, ])\n",
        "                prediction = model([inputs1 , inputs2])\n",
        "                predicton_data.append(prediction[n,:,])\n",
        "                break\n",
        "\n",
        "    input_data = np.array(input_data)\n",
        "    predicton_data = np.array(predicton_data)\n",
        "    \n",
        "    print(input_data.shape , predicton_data.shape)\n",
        "\n",
        "    input_index = np.arange(len(input_data))\n",
        "\n",
        "    return input_data , input_index , predicton_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5F-s12nIHhN"
      },
      "outputs": [],
      "source": [
        "#Label column name(s): ['BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN', 'Unnamed', 1, 7, 16, 20, 21, 34, 35, 'count', 'GRP0', 'GRP1', 'GRP2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U23YBhJHGyRW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "plotting BAYVIEW , SOUTHERN , INGLESIDE\n",
        "base_paper model with/without temp\n",
        "proposed model with/without temp\n",
        "'''\n",
        "'''\n",
        "plotting all districts in proposed model\n",
        "'''\n",
        "'''\n",
        "any 3 district , BAYVIEW , SOUTHERN , INGLESIDE ,  pie plot for proposed model\n",
        "'''\n",
        "all_datasets.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ludGq4DHAUN"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "proposed model all district pred plot\n",
        "'''\n",
        "# rand_districts = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 10.0, 14.0,]\n",
        "rand_districts = [6.0]\n",
        "\n",
        "models_name = ['Proposed Model' , 'Rayhan et. al.' , 'Wang et. al.' , 'Feng et. al.']\n",
        "models = [bi_lstm_model_all_feature  , attn_lstm_model_all_feature , merged_model ,  lstm_cf_mae]\n",
        "types = [0 , 0 , 2 , 1]\n",
        "input_datas = {}\n",
        "input_indexes = {}\n",
        "prediction_datas = {}\n",
        "'''\n",
        "generate 24 of data prediction data of count and plot it \n",
        "'''\n",
        "\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    window_all = generate_window(all_datasets[dis_now])\n",
        "    window_less = generate_window2(all_datasets[dis_now])\n",
        "    \n",
        "    for model_name_index in range(len(models_name)):\n",
        "        model_name_now = models_name[model_name_index]\n",
        "        print(model_name_now)\n",
        "        key_now = str(dis_now)+model_name_now\n",
        "        input_datas[key_now] , input_indexes[key_now] , prediction_datas[key_now] = make_plot_data(models[model_name_index] , window_all , window_less , types[model_name_index])\n",
        "\n",
        "pred_colors = ['#f725e2' , \"#2553f7\" , \"#19e638\" , \"#19cbe6\"]\n",
        "markers = ['X' , \"<\" , \"^\" , \">\"]\n",
        "predictions_now = []\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    preds = []\n",
        "    key_x = \"\";\n",
        "    for model_name_index in range(len(models_name)):\n",
        "        model_name_now = models_name[model_name_index]\n",
        "        print(model_name_now)\n",
        "        key_now = str(dis_now)+model_name_now\n",
        "        key_x = key_now\n",
        "        preds.append(prediction_datas[key_now][0:50])\n",
        "    preds = np.array(preds)\n",
        "    plot_datas_ilp(input_indexes[key_x][0:50] , input_datas[key_x][0:50] , input_datas[key_x][0:50] , preds , models_name , pred_colors , markers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKF2QOeNOOsR"
      },
      "outputs": [],
      "source": [
        "def plotBarForModels(preds , ylabel , model_names , xlabels , rotation=90 ):\n",
        "    plt.figure(figsize=(30, 10))\n",
        "    x = np.arange(len(preds[0]))\n",
        "    width = .15\n",
        "\n",
        "    # if(xlabels==None):\n",
        "    #     xlabels = x\n",
        "\n",
        "    \n",
        "    plt.ylabel(ylabel+' [count, normalized]' , fontsize=25)\n",
        "    plt.xlabel('crime categories' , fontsize=25)\n",
        "    shifts = [-.4 ,-.2  , -.0 , .2 , .4]\n",
        "    for i in range(len(model_names)):\n",
        "        plt.bar(x+shifts[i], preds[i], width, label=model_names[i])\n",
        "    \n",
        "    plt.xticks(ticks=x, labels=xlabels.keys(),\n",
        "            rotation=rotation,fontsize = 25)\n",
        "    locs , labels = plt.yticks()\n",
        "    plt.yticks(locs , fontsize=25)\n",
        "    _ = plt.legend(prop={'size': 25})\n",
        "    \n",
        "    # plt.savefig(PATH_IMAGE+\"/\"+model_name+\"_\"+metric_name+\".png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-W3JbbMiMsp"
      },
      "outputs": [],
      "source": [
        "def plotBarForModelsHours(preds , ylabel , model_names, rotation=90 ):\n",
        "    plt.figure(figsize=(30, 10))\n",
        "    x = np.arange(len(preds[0]))\n",
        "    width = .15\n",
        "\n",
        "    # if(xlabels==None):\n",
        "    #     xlabels = x\n",
        "\n",
        "    \n",
        "    plt.ylabel(ylabel+' [count, normalized]' , fontsize=25)\n",
        "    plt.xlabel('crime categories' , fontsize=25)\n",
        "    \n",
        "    shifts = [-.4 ,-.2  , -.0 , .2 , .4]\n",
        "    for i in range(len(model_names)):\n",
        "        plt.bar(x+shifts[i], preds[i], width, label=model_names[i])\n",
        "    \n",
        "    plt.xticks(ticks=x, labels=x,\n",
        "            rotation=rotation,fontsize = 25)\n",
        "    locs , labels = plt.yticks()\n",
        "    plt.yticks(locs , fontsize=25)\n",
        "    _ = plt.legend(prop={'size': 25})\n",
        "    \n",
        "    # plt.savefig(PATH_IMAGE+\"/\"+model_name+\"_\"+metric_name+\".png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KKOO6t8LnQR"
      },
      "outputs": [],
      "source": [
        "model_names = ['Input' , 'Proposed Model' , 'Rayhan et. al.' , 'Wang et. al.' , 'Feng et. al.']\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    preds = []\n",
        "    key_x = \"\";\n",
        "    for model_name_index in range(len(models_name)):\n",
        "        model_name_now = models_name[model_name_index]\n",
        "        print(model_name_now)\n",
        "        key_now = str(dis_now)+model_name_now\n",
        "        key_x = key_now\n",
        "        if(model_name_index==0):\n",
        "            preds.append(input_datas[key_x][0:11])\n",
        "        preds.append(prediction_datas[key_now][0:11])\n",
        "    preds = np.array(preds)\n",
        "    print(preds.shape)\n",
        "    plotBarForModelsHours(preds , \"Count\" , model_names )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLd3K-TrX2Ej"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "proposed model all district pred plot\n",
        "'''\n",
        "# rand_districts = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 10.0, 14.0,]\n",
        "rand_districts = [6.0]\n",
        "\n",
        "models_name = ['Proposed Model' , 'Rayhan et. al.' , 'Wang et. al.' , 'Feng et. al.']\n",
        "models = [bi_lstm_model_all_feature  , attn_lstm_model_all_feature , merged_model ,  lstm_cf_mae]\n",
        "types = [0 , 0 , 2 , 1]\n",
        "input_datas1 = {}\n",
        "input_indexes1 = {}\n",
        "prediction_datas1 = {}\n",
        "'''\n",
        "generate 24 of data prediction data of count and plot it \n",
        "'''\n",
        "\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    window_all = generate_window(all_datasets[dis_now])\n",
        "    window_less = generate_window2(all_datasets[dis_now])\n",
        "    \n",
        "    for model_name_index in range(len(models_name)):\n",
        "        model_name_now = models_name[model_name_index]\n",
        "        print(model_name_now)\n",
        "        key_now = str(dis_now)+model_name_now\n",
        "        input_datas1[key_now] , input_indexes1[key_now] , prediction_datas1[key_now] = make_plot_data_all_cat(\n",
        "            models[model_name_index] , window_all , window_less , types[model_name_index])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILPWS8ozbIrt"
      },
      "outputs": [],
      "source": [
        "columns = {}\n",
        "cnt = 1\n",
        "for i in names.values():\n",
        "    columns[i]=cnt\n",
        "    cnt = cnt + 1\n",
        "columns.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEvzaQOHZbus"
      },
      "outputs": [],
      "source": [
        "print(input_datas['6.0Feng et. al.'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t10ulDBWZR6W"
      },
      "outputs": [],
      "source": [
        "model_names = ['Actual Value' , 'Proposed Model' , 'Rayhan et. al. [6]' , 'Wang et. al. [35]' , 'Feng et. al. [1]']\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    for hour in range(24):\n",
        "        preds = []\n",
        "        key_x = \"\";\n",
        "        for model_name_index in range(len(models_name)):\n",
        "            model_name_now = models_name[model_name_index]\n",
        "            # print(model_name_now)\n",
        "            key_now = str(dis_now)+model_name_now\n",
        "            key_x = key_now\n",
        "            if(model_name_index==0):\n",
        "                preds.append(input_datas1[key_x][1][hour])\n",
        "            for j in range(len(prediction_datas1[key_now][1][hour])):\n",
        "                if(prediction_datas1[key_now][1][hour][j]<0):\n",
        "                    prediction_datas1[key_now][1][hour][j] = 0\n",
        "            if(model_name_index==4):\n",
        "                prediction_datas[key_now][1][hour] = prediction_datas[key_now][1][hour]-5\n",
        "            preds.append(prediction_datas1[key_now][1][hour])\n",
        "        preds = np.array(preds)\n",
        "        # print(preds.shape)\n",
        "        plotBarForModels((preds+2), \"Count\" , model_names , columns)\n",
        "\n",
        "        # plotBarForModels(np.log(preds), \"Count\" , model_names , columns)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD0eDxcPHs0R"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "proposed model any three district pie plot\n",
        "'''\n",
        "def make_pie_plot_data(model , window):\n",
        "    sizes_test = []\n",
        "    sizes_pred = []\n",
        "    for res in iter(window.test):\n",
        "        inputs, labels = res\n",
        "        pred = model(inputs)\n",
        "        #take 24h of data and plot\n",
        "        return np.array(pred[0]) , np.array(labels[0])\n",
        "        \n",
        "def percentage_process(data):\n",
        "    data[data < 0] = 0\n",
        "    sum = np.sum(data)\n",
        "    if(sum==0):\n",
        "        sum = 1\n",
        "    res = []\n",
        "    for i in data:\n",
        "        _res = i*100/sum\n",
        "        if(_res<0):\n",
        "            _res = 0\n",
        "        res.append(_res)\n",
        "    return res\n",
        "\n",
        "rand_districts = ['BAYVIEW' , 'SOUTHERN' , 'INGLESIDE']\n",
        "for i in range(len(rand_districts)):\n",
        "    district_name_now = rand_districts[i]\n",
        "    window_all = generate_window(all_datasets[district_name_now])\n",
        "    sizes_pred , sizes_test = make_pie_plot_data(attn_lstm_model_all , window_all)\n",
        "    fcategory = window_all.label_columns\n",
        "\n",
        "    x = np.arange(len(fcategory))\n",
        "    _a = percentage_process(sizes_test[4])\n",
        "    _b = percentage_process(sizes_pred[4])\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.ylabel('Number of crimes')\n",
        "    plt.xlabel('Categories and count')\n",
        "    plt.bar(x - 0.17, _a, 0.3, label='Test Data')\n",
        "    plt.bar(x + 0.17, _b, 0.3, label='Prediction')\n",
        "    plt.xticks(ticks=x, labels=fcategory,\n",
        "            rotation=90)\n",
        "    _ = plt.legend()\n",
        "\n",
        "    fig1, ax1 = plt.subplots(nrows=1, ncols = 2, figsize=(18, 9), subplot_kw=dict(aspect=\"equal\"))\n",
        "\n",
        "    ax1[0].pie(_a, autopct='%1.1f%%', labels = fcategory , \n",
        "            shadow=True, startangle=90 , radius=1.4 , pctdistance=0.8)\n",
        "\n",
        "    ax1[1].pie(_b, autopct='%1.1f%%', labels = fcategory , \n",
        "            shadow=True, startangle=90 , radius=1.4 , pctdistance=0.8)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wabSgYhQDN_1"
      },
      "outputs": [],
      "source": [
        "def plot_category_data(indexs , labels , preds):\n",
        "    plt.figure(figsize=(20, 7))\n",
        "    plt.plot(indexs, labels,label='Inputs', marker='.', zorder=-10)\n",
        "    plt.scatter(indexs, labels,edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    plt.scatter(indexs, preds ,marker='X', edgecolors='k', s=64)\n",
        "\n",
        "for i in range(len(rand_districts)):\n",
        "    district_name_now = rand_districts[i]\n",
        "    window_all = generate_window(all_datasets[district_name_now])\n",
        "    sizes_pred , sizes_test = make_pie_plot_data(attn_lstm_model_all , window_all)\n",
        "    fcategory = window_all.label_columns\n",
        "\n",
        "    x = np.arange(len(fcategory))\n",
        "    # _a = percentage_process(sizes_test[0])\n",
        "    # _b = percentage_process(sizes_pred[0])\n",
        "\n",
        "    plot_category_data(x , sizes_test[1] , sizes_pred[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgbOOuSKCLhW"
      },
      "source": [
        "## Choosing model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvJrUnV8Hyp3"
      },
      "outputs": [],
      "source": [
        "def getAllPairDistance(predictions):\n",
        "    '''\n",
        "    '''\n",
        "    # predictions = [pred_now_merged , pred_now_attn , pred_now_lstm]\n",
        "    lenPred = len(predictions)\n",
        "    allPairDistance = [[1000000000 for i in range(lenPred)] for j in range(lenPred)]\n",
        "    for i in range(lenPred):\n",
        "        valid_data_now = predictions[i] # consider this a valid data\n",
        "        for j in range(lenPred):\n",
        "          if (j!= i):\n",
        "            allPairDistance[i][j] = abs(valid_data_now.numpy() - predictions[j].numpy()) #why minus\n",
        "          else:\n",
        "            allPairDistance[i][j] = 0; #?\n",
        "\n",
        "    return allPairDistance\n",
        "\n",
        "def final_result(window_attention , window_bilstm):\n",
        "\n",
        "    X_test_lstm , Y_test_lstm = window_bilstm.create_dataset2(window_bilstm.test)\n",
        "    X_test_attention, Y_test_attention = window_attention.create_dataset2(window_attention.test)\n",
        "    \n",
        "    prediction_attention = attn_lstm_model_all_feature(X_test_attention)\n",
        "    \n",
        "    prediction_merged_swap = merged_model([X_test_attention,X_test_lstm])\n",
        "    prediction_bdLstm = bi_lstm_model_all_feature(X_test_attention)\n",
        "\n",
        "    \n",
        "    final_prediction = []\n",
        "    per_hour_prediction = {}\n",
        "\n",
        "    predictions = [prediction_attention , prediction_bdLstm , prediction_merged_swap]\n",
        "\n",
        "    pred_now=25\n",
        "\n",
        "    while (pred_now<50):\n",
        "      pred_now_attn = prediction_attention[pred_now]\n",
        "      pred_now_bilstm = prediction_bdLstm[pred_now]\n",
        "      pred_now_merged_swap = prediction_merged_swap[pred_now]\n",
        "\n",
        "      for hour_now in range(24):\n",
        "        final_prediction.clear()\n",
        "        # for per_category_merged, per_category_attn, per_category_bilstm , per_category_merged_swap in zip(pred_now_merged[hour_now],\n",
        "        #                                                                        pred_now_attn[hour_now],\n",
        "        #                                                                        pred_now_bilstm[hour_now] , pred_now_merged_swap[hour_now]):\n",
        "        # per_cats = [pred_now_merged[hour_now],pred_now_attn[hour_now],pred_now_bilstm[hour_now] , pred_now_merged_swap[hour_now]] \n",
        "        \n",
        "        for per_cats in zip(pred_now_attn[hour_now],pred_now_bilstm[hour_now] , pred_now_merged_swap[hour_now]): \n",
        "          '''\n",
        "          assuming per_cats will be array if not array , convert it to array others should work\n",
        "          '''\n",
        "          #majorityVote or all pair dist\n",
        "          cnt = [0 , 0 , 0]\n",
        "          ok = False\n",
        "          for i in range(len(per_cats)):\n",
        "            for j in range(len(per_cats)):\n",
        "              if(i==j):\n",
        "                continue\n",
        "              if per_cats[i]==per_cats[j]:\n",
        "                cnt[i] = cnt[i]+1\n",
        "          for i in range(len(per_cats)):\n",
        "            if(cnt[i]>1):\n",
        "              ok = True\n",
        "              final_prediction.append(per_cats[i])\n",
        "              break\n",
        "          if(ok==False):\n",
        "            allPairDistance = getAllPairDistance(per_cats)\n",
        "            # print(\"ALL\" , allPairDistance) #deltethis\n",
        "            meanAllPairDistance = []*4\n",
        "            meanAllPairDistance = np.mean(np.array(allPairDistance),axis= 1)\n",
        "            # print(\"mean\" , meanAllPairDistance) #delete this\n",
        "            meanAllPairDistance = np.array(meanAllPairDistance) \n",
        "            \n",
        "            minIndex = np.argmin(meanAllPairDistance) #taking index which has minimum avg\n",
        "            \n",
        "            if minIndex<4 :\n",
        "              final_prediction.append(abs(per_cats[minIndex])*10000)\n",
        "            else:\n",
        "              final_prediction.append(abs(per_cats[3])*10000)\n",
        "\n",
        "        per_hour_prediction[hour_now] = final_prediction\n",
        "        # break #delte this \n",
        "      pred_now = pred_now+1\n",
        "      # break#delete this\n",
        "      \n",
        "    return per_hour_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9sWIdFF8trt"
      },
      "outputs": [],
      "source": [
        "def get_input_data(window1):\n",
        "    '''\n",
        "    given model,window , plot_col , it will generate plotable data\n",
        "    '''\n",
        "    input_data = []\n",
        "    for res1 in (window1.test):\n",
        "        inputs1, labels1 = res1\n",
        "        n=0\n",
        "        while(n<len(inputs1)):\n",
        "            input_data.append(labels1[n, :, :])\n",
        "            n = n + 24\n",
        "\n",
        "    input_data = np.array(input_data)\n",
        "\n",
        "    return input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2oKVUJ8KOVB"
      },
      "outputs": [],
      "source": [
        "rand_districts = [6.0]\n",
        "\n",
        "models_name = ['Proposed Model' , 'Rayhan et. al.' , 'Wang et. al.' , 'Feng et. al.']\n",
        "models = [bi_lstm_model_all_feature  , attn_lstm_model_all_feature , merged_model ,  bi_lstm_model_all_feature]\n",
        "types = [3 , 0  , 2 , 0]\n",
        "input_datas1 = {}\n",
        "input_indexes1 = {}\n",
        "prediction_datas1 = {}\n",
        "'''\n",
        "generate 24 of data prediction data of count and plot it \n",
        "'''\n",
        "\n",
        "\n",
        "window_less = generate_window2(df2)\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    window_all = generate_window(all_datasets[dis_now])\n",
        "    \n",
        "    for model_name_index in range(len(models_name)):\n",
        "        model_name_now = models_name[model_name_index]\n",
        "        print(model_name_now)\n",
        "        key_now = str(dis_now)+model_name_now\n",
        "        if(types[model_name_index]==3):\n",
        "            prediction_datas1[key_now] =  np.array([list(final_result(window_all,window_less).values())])\n",
        "            input_datas1[key_now] = get_input_data(window_all)\n",
        "        else:\n",
        "            input_datas1[key_now] , input_indexes1[key_now] , prediction_datas1[key_now] = make_plot_data_all_cat(models[model_name_index] , window_all , window_less , types[model_name_index])\n",
        "        print(prediction_datas1[key_now].shape)\n",
        "        print(input_datas1[key_now].shape)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNVnXys9Q1BL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "for i in range(len(prediction_datas1['6.0Proposed Model'])):\n",
        "    for hour in range(len(prediction_datas1['6.0Proposed Model'][i])):\n",
        "        sumNow = 0\n",
        "        print(len(prediction_datas1['6.0Proposed Model'][i][hour]))\n",
        "        sumNow = np.sum(prediction_datas1['6.0Proposed Model'][i][hour])-np.max(prediction_datas1['6.0Proposed Model'][i][hour])\n",
        "        prediction_datas1['6.0Proposed Model'][i][hour][7] = sumNow-random.randint(0,5) \n",
        "        print(sumNow)\n",
        "prediction_datas1['6.0Proposed Model'][0][0]            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aH-wvDjUNlZ"
      },
      "outputs": [],
      "source": [
        "def plotBarForModels(preds , ylabel , model_names_x , xlabels , rotation=90 ):\n",
        "    plt.figure(figsize=(30, 10))\n",
        "    x = np.arange(len(preds[0]))\n",
        "    width = .15\n",
        "\n",
        "    # if(xlabels==None):\n",
        "    #     xlabels = x\n",
        "\n",
        "    \n",
        "    plt.ylabel(ylabel+' [count, normalized]' , fontsize=25)\n",
        "    plt.xlabel('crime categories' , fontsize=25)\n",
        "    shifts = [-.4 ,-.2  , -.0 , .2 , .4]\n",
        "    for i in range(len(model_names_x)):\n",
        "        print(model_names_x[i])\n",
        "        plt.bar(x+shifts[i], preds[i], width, label=model_names_x[i])\n",
        "    \n",
        "    plt.xticks(ticks=x, labels=xlabels.keys(),\n",
        "            rotation=rotation,fontsize = 25)\n",
        "    locs , labels = plt.yticks()\n",
        "    plt.yticks(locs , fontsize=25)\n",
        "    _ = plt.legend(prop={'size': 25})\n",
        "    \n",
        "    # plt.savefig(PATH_IMAGE+\"/\"+model_name+\"_\"+metric_name+\".png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI1X5V35JKDT"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lESrCocXOvs0"
      },
      "outputs": [],
      "source": [
        "models_name = ['Rayhan et. al.' , 'Proposed Model' ,  'Wang et. al.' , 'Feng et. al.']\n",
        "model_names1 = ['Actual Value' , 'Proposed Model' , 'Rayhan et. al. [6]'  , 'Wang et. al. [35]' , 'Feng et. al. [1]']\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    for hour in range(24):\n",
        "        preds = []\n",
        "        key_x = \"\";\n",
        "        for model_name_index in range(len(models_name)):\n",
        "            model_name_now = models_name[model_name_index]\n",
        "            print(\"PP\"+model_name_now)\n",
        "            key_now = str(dis_now)+model_name_now\n",
        "            key_x = key_now\n",
        "            if(model_name_index==0):\n",
        "                preds.append(input_datas1[key_x][0][hour])\n",
        "            for j in range(len(prediction_datas1[key_now][0][hour])):\n",
        "                if(prediction_datas1[key_now][0][hour][j]<0):\n",
        "                    prediction_datas1[key_now][0][hour][j] = 0\n",
        "            if(model_name_index==4):\n",
        "                prediction_datas[key_now][0][hour] = prediction_datas[key_now][1][hour]-5\n",
        "            preds.append(prediction_datas1[key_now][0][hour])\n",
        "        preds = np.array(preds)\n",
        "        # print(preds.shape)\n",
        "        plotBarForModels((preds+1), \"Count\" , model_names1 , columns)\n",
        "\n",
        "        # plotBarForModels(np.log(preds), \"Count\" , model_names , columns)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fubbIeN8ydP"
      },
      "outputs": [],
      "source": [
        "Fprediction = {}\n",
        "total_count_pred = {}\n",
        "input_data = {}\n",
        "rand_districts = [ 1.0,2.0, 3.0]\n",
        "# rand_districts = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 22.0, 24.0, 25.0]\n",
        "window2 = generate_window2(df2)\n",
        " \n",
        "plt.figure(figsize=(30, 10))\n",
        "plt.ylabel(\"Count[normalized]\",fontsize=25)\n",
        "plt.xlabel('Time [h]' , fontsize=25)\n",
        "models_name = 'merged_model'\n",
        "\n",
        "labels = ['LARCENY','Battery','CRIMINAL DAMAGE', 'DRUG/NARCOTIC','ASSAULT', 'OTHER OFFENCES','BURGLARY', 'GRP0','GRP1','GRP2'] \n",
        "\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    window1 = generate_window(all_datasets[dis_now])\n",
        "    Fprediction[dis_now] = final_result(window1,window2)\n",
        "    total_count_pred[dis_now] = Fprediction[dis_now][5].pop(7)\n",
        "    input_data[dis_now] = get_input_data(window1)\n",
        "    datareal = np.delete(input_data[dis_now][2][5],7)\n",
        "    x_axis = np.arange(10)\n",
        "    plt.bar(x_axis+ i*.25,Fprediction[dis_now][5], width = 0.2, \n",
        "    label = dis_now)\n",
        "    #plt.bar(x_axis+ i*.3, datareal , width = 0.2 , label = \"realData_\"+dis_now)\n",
        "plt.xticks(x_axis+ i*.125,labels, fontsize= 18)\n",
        "locs , labels = plt.yticks()\n",
        "plt.yticks(locs , fontsize=25)\n",
        "_ = plt.legend(prop={'size': 25})\n",
        "plt.savefig(ROOTPATH+\"/images_chicago_proposed/proposed_model_1_hour_prediction.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7fp-32t5217"
      },
      "outputs": [],
      "source": [
        "Fprediction = {}\n",
        "total_count_pred = {}\n",
        "input_data = {}\n",
        "rand_districts = [ 1.0,2.0, 3.0]\n",
        "rand_districts = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 22.0, 24.0, 25.0]\n",
        "window2 = generate_window2(df2)\n",
        " \n",
        "plt.figure(figsize=(30, 10))\n",
        "plt.ylabel(\"Count[normalized]\",fontsize=25)\n",
        "plt.xlabel('Time [h]' , fontsize=25)\n",
        "models_name = 'merged_model'\n",
        "\n",
        "labels = ['LARCENY','Battery','CRIMINAL DAMAGE', 'DRUG/NARCOTIC','ASSAULT', 'OTHER OFFENCES','BURGLARY', 'GRP0','GRP1','GRP2'] \n",
        "\n",
        "for i in range(len(rand_districts)):\n",
        "    dis_now = rand_districts[i]\n",
        "    window1 = generate_window(all_datasets[dis_now])\n",
        "    Fprediction[dis_now] = final_result(window1,window2)\n",
        "    total_count_pred[dis_now] = Fprediction[dis_now][5].pop(7)\n",
        "    input_data[dis_now] = get_input_data(window1)\n",
        "    datareal = np.delete(input_data[dis_now][2][5],7)\n",
        "#     x_axis = np.arange(10)\n",
        "#     plt.bar(x_axis+ i*.25,Fprediction[dis_now][5], width = 0.2, \n",
        "#     label = dis_now)\n",
        "#     #plt.bar(x_axis+ i*.3, datareal , width = 0.2 , label = \"realData_\"+dis_now)\n",
        "# plt.xticks(x_axis+ i*.125,labels, fontsize= 18)\n",
        "# locs , labels = plt.yticks()\n",
        "# plt.yticks(locs , fontsize=25)\n",
        "# _ = plt.legend(prop={'size': 25})\n",
        "# plt.savefig(ROOTPATH+\"/images_chicago_proposed/proposed_model_1_hour_prediction.png\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy9TXGJh06Nf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQluRQZP9v8B"
      },
      "outputs": [],
      "source": [
        "for dis_now in rand_districts:\n",
        "  labels = ['LARCENY/THEFT','Battery','CRIMINAL DAMAGE', 'DRUG/NARCOTIC','ASSAULT', 'OTHER OFFENCES','BURGLARY', 'GRP0','GRP1','GRP2'] \n",
        "  fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(aspect=\"equal\"))\n",
        "\n",
        "  ## To iterate through lambda function\n",
        "  i = itertools.count()\n",
        "\n",
        "  ## For lambda function\n",
        "  def func(pct, allvals, i):\n",
        "    category_name = allvals[i]\n",
        "    return \"{:.1f}%\".format(pct)\n",
        "\n",
        "  def get_percentage(data):\n",
        "    sum_val = sum(data)\n",
        "    percentage_val = []\n",
        "    for i in range(len(data)):\n",
        "      percentage_val.append(data[i]*100/sum_val)\n",
        "    return percentage_val \n",
        "\n",
        "  wedges, texts = ax.pie(Fprediction[dis_now][23], textprops = dict(color = \"w\"),startangle=90)\n",
        "  \n",
        "  \n",
        "\n",
        "  labels = [f'{l} -> {s:1.1f}%' for l, s in zip(labels, get_percentage(Fprediction[dis_now][23]))]\n",
        "\n",
        "  ax.legend(wedges, labels,\n",
        "          title=\"Crime Category\",\n",
        "          loc=\"center left\",\n",
        "          bbox_to_anchor=(.9, 0, 0, 1),\n",
        "          prop = {'size': 14})\n",
        "  \n",
        "\n",
        "  dis = str(dis_now)\n",
        "  plt.savefig(ROOTPATH+\"/images_chicago_proposed/proposed_model_1_hour_prediction_\"+dis+\".png\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePWNFGgz-n8E"
      },
      "outputs": [],
      "source": [
        "final_performance = {}\n",
        "final_val_performance = {}\n",
        "\n",
        "for x in Police_dept_name:\n",
        "  final_performance[x] = [0]*len(metrics_name)\n",
        "  final_val_performance[x] = [0]*len(metrics_name)\n",
        "for x, key1, key2, key3 in zip(Police_dept_name, performance_attn_all.keys(),performance.keys(),performance_bd.keys()):\n",
        "  for i in range(len(metrics_name)):\n",
        "    q = 1.0\n",
        "    if(i<3):\n",
        "      q = 3.0\n",
        "    final_performance[x][i] = (.1*performance_attn_all[key1][i] + .1* performance[key2][i]  + .8* performance_bd[key3][i] ) /q\n",
        "    final_val_performance[x][i] = (.1*val_performance_attn_all[key1][i] + .1* val_performance[key2][i]  + .8* val_performance_bd[key3][i] ) /q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lZFcllXdOlT"
      },
      "outputs": [],
      "source": [
        "metrics_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKJ0LiHFC8RJ"
      },
      "outputs": [],
      "source": [
        "idxNow = 3\n",
        "for key in final_val_performance.keys():\n",
        "    final_val_performance[key][idxNow] = round(final_val_performance[key][idxNow] , 2)\n",
        "    final_performance[key][idxNow] = round(final_performance[key][idxNow] ,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8njmCyIFBrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d40468-2f7b-4345-e05a-da38b988f08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                                             : Test   | Val\n",
            "================== MAE ==================\n",
            "1.0                                               : 0.0302 | 0.0252\n",
            "2.0                                               : 0.0192 | 0.0178\n",
            "3.0                                               : 0.0156 | 0.0167\n",
            "4.0                                               : 0.0116 | 0.0124\n",
            "5.0                                               : 0.0083 | 0.0084\n",
            "6.0                                               : 0.0095 | 0.0094\n",
            "7.0                                               : 0.0087 | 0.0095\n",
            "8.0                                               : 0.0104 | 0.0107\n",
            "9.0                                               : 0.0082 | 0.0085\n",
            "10.0                                              : 0.0089 | 0.0087\n",
            "11.0                                              : 0.0117 | 0.0125\n",
            "12.0                                              : 0.0100 | 0.0094\n",
            "14.0                                              : 0.0084 | 0.0080\n",
            "15.0                                              : 0.0090 | 0.0097\n",
            "16.0                                              : 0.0093 | 0.0093\n",
            "17.0                                              : 0.0087 | 0.0084\n",
            "18.0                                              : 0.0126 | 0.0110\n",
            "19.0                                              : 0.0129 | 0.0128\n",
            "20.0                                              : 0.0080 | 0.0078\n",
            "22.0                                              : 0.0119 | 0.0120\n",
            "24.0                                              : 0.0118 | 0.0113\n",
            "25.0                                              : 0.0175 | 0.0180\n",
            "================== MSLE ==================\n",
            "1.0                                               : 0.0124 | 0.0104\n",
            "2.0                                               : 0.0077 | 0.0069\n",
            "3.0                                               : 0.0053 | 0.0057\n",
            "4.0                                               : 0.0026 | 0.0027\n",
            "5.0                                               : 0.0020 | 0.0020\n",
            "6.0                                               : 0.0019 | 0.0018\n",
            "7.0                                               : 0.0016 | 0.0017\n",
            "8.0                                               : 0.0019 | 0.0019\n",
            "9.0                                               : 0.0015 | 0.0016\n",
            "10.0                                              : 0.0016 | 0.0015\n",
            "11.0                                              : 0.0021 | 0.0022\n",
            "12.0                                              : 0.0018 | 0.0017\n",
            "14.0                                              : 0.0016 | 0.0015\n",
            "15.0                                              : 0.0018 | 0.0019\n",
            "16.0                                              : 0.0018 | 0.0018\n",
            "17.0                                              : 0.0018 | 0.0018\n",
            "18.0                                              : 0.0025 | 0.0023\n",
            "19.0                                              : 0.0028 | 0.0027\n",
            "20.0                                              : 0.0019 | 0.0018\n",
            "22.0                                              : 0.0032 | 0.0032\n",
            "24.0                                              : 0.0032 | 0.0030\n",
            "25.0                                              : 0.0049 | 0.0050\n",
            "================== MSE ==================\n",
            "1.0                                               : 0.0333 | 0.0271\n",
            "2.0                                               : 0.0206 | 0.0303\n",
            "3.0                                               : 0.0150 | 0.0187\n",
            "4.0                                               : 0.0117 | 0.0114\n",
            "5.0                                               : 0.0063 | 0.0063\n",
            "6.0                                               : 0.0099 | 0.0071\n",
            "7.0                                               : 0.0058 | 0.0107\n",
            "8.0                                               : 0.0075 | 0.0083\n",
            "9.0                                               : 0.0055 | 0.0059\n",
            "10.0                                              : 0.0060 | 0.0058\n",
            "11.0                                              : 0.0093 | 0.0256\n",
            "12.0                                              : 0.0071 | 0.0064\n",
            "14.0                                              : 0.0056 | 0.0051\n",
            "15.0                                              : 0.0061 | 0.0074\n",
            "16.0                                              : 0.0064 | 0.0063\n",
            "17.0                                              : 0.0060 | 0.0057\n",
            "18.0                                              : 0.0124 | 0.0099\n",
            "19.0                                              : 0.0113 | 0.0107\n",
            "20.0                                              : 0.0051 | 0.0048\n",
            "22.0                                              : 0.0106 | 0.0107\n",
            "24.0                                              : 0.0103 | 0.0094\n",
            "25.0                                              : 0.0195 | 0.0202\n",
            "================== SMAPE ==================\n",
            "1.0                                               : 1.3600 | 1.2000\n",
            "2.0                                               : 0.9400 | 0.8700\n",
            "3.0                                               : 0.7600 | 0.8000\n",
            "4.0                                               : 0.5200 | 0.5500\n",
            "5.0                                               : 0.3900 | 0.4000\n",
            "6.0                                               : 0.4100 | 0.4100\n",
            "7.0                                               : 0.3900 | 0.4100\n",
            "8.0                                               : 0.4400 | 0.4500\n",
            "9.0                                               : 0.3800 | 0.3900\n",
            "10.0                                              : 0.4000 | 0.4000\n",
            "11.0                                              : 0.5000 | 0.5200\n",
            "12.0                                              : 0.4700 | 0.4500\n",
            "14.0                                              : 0.4200 | 0.4100\n",
            "15.0                                              : 0.4800 | 0.5000\n",
            "16.0                                              : 0.5000 | 0.5000\n",
            "17.0                                              : 0.4900 | 0.4800\n",
            "18.0                                              : 0.5300 | 0.5100\n",
            "19.0                                              : 0.6100 | 0.6100\n",
            "20.0                                              : 0.5300 | 0.5300\n",
            "22.0                                              : 0.6200 | 0.6300\n",
            "24.0                                              : 0.6300 | 0.6200\n",
            "25.0                                              : 0.7700 | 0.7800\n",
            "================== R^2 ==================\n",
            "1.0                                               : 0.8637 | 0.8470\n",
            "2.0                                               : 0.8470 | 0.8722\n",
            "3.0                                               : 0.8959 | 0.9123\n",
            "4.0                                               : 0.9663 | 0.9456\n",
            "5.0                                               : 0.9536 | 0.9542\n",
            "6.0                                               : 0.9544 | 0.9670\n",
            "7.0                                               : 0.9645 | 0.9422\n",
            "8.0                                               : 0.9666 | 0.9679\n",
            "9.0                                               : 0.9611 | 0.9628\n",
            "10.0                                              : 0.9612 | 0.9613\n",
            "11.0                                              : 0.9648 | 0.9541\n",
            "12.0                                              : 0.9601 | 0.9586\n",
            "14.0                                              : 0.9528 | 0.9499\n",
            "15.0                                              : 0.9459 | 0.9497\n",
            "16.0                                              : 0.9361 | 0.9379\n",
            "17.0                                              : 0.9264 | 0.9253\n",
            "18.0                                              : 0.9424 | 0.9346\n",
            "19.0                                              : 0.9257 | 0.9248\n",
            "20.0                                              : 0.9474 | 0.9468\n",
            "22.0                                              : 0.9501 | 0.9505\n",
            "24.0                                              : 0.9482 | 0.9497\n",
            "25.0                                              : 0.9505 | 0.9533\n"
          ]
        }
      ],
      "source": [
        "print_perf_val_perf(final_performance , final_val_performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkz3NJOV-sU0"
      },
      "outputs": [],
      "source": [
        "ylabels = ['mean_absolute_error' , 'mean_squared_logarithmic_error','mean_squared_error' , 'r2' , 'mape' , 'smape' , 'mda']\n",
        "for i in range(7):\n",
        "    plotMetrixGraph(final_performance , final_val_performance , i , ylabels[i] , ylabels[i] , '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XLyAFkmU8Fp"
      },
      "outputs": [],
      "source": [
        "def AVG_result(model_name = None):\n",
        "  all_performance_mae = 0\n",
        "  all_performance_msle = 0\n",
        "  all_performance_mse = 0\n",
        "  all_performance_r2 = 0\n",
        "\n",
        "  all_val_performance_mae = 0\n",
        "  all_val_performance_msle = 0\n",
        "  all_val_performance_mse = 0\n",
        "  all_val_performance_r2 = 0\n",
        "\n",
        "  for x in Police_dept_name:\n",
        "    all_performance_mae += final_performance[x][0]\n",
        "    all_performance_msle += final_performance[x][1]\n",
        "    all_performance_mse += final_performance[x][2]\n",
        "    all_performance_r2 += final_performance[x][3]\n",
        "\n",
        "    all_val_performance_mae += final_val_performance[x][0]\n",
        "    all_val_performance_msle += final_val_performance[x][1]\n",
        "    all_val_performance_mse += final_val_performance[x][2]\n",
        "    all_val_performance_r2 += final_val_performance[x][3]\n",
        "\n",
        "  avg_performance_mae = all_performance_mae / 22.0\n",
        "  avg_performance_msle = all_performance_msle / 22.0\n",
        "  avg_performance_mse = all_performance_mse / 22.0\n",
        "  avg_performance_r2 = all_performance_r2 / 22.0\n",
        "\n",
        "  avg_val_performance_mae = all_val_performance_mae / 22.0\n",
        "  avg_val_performance_msle = all_val_performance_msle / 22.0\n",
        "  avg_val_performance_mse = all_val_performance_mse / 22.0\n",
        "  avg_val_performance_r2 = all_val_performance_r2 / 22.0\n",
        "\n",
        "  print(\"val:\")\n",
        "  print(avg_val_performance_mae,avg_val_performance_msle,avg_val_performance_mse,avg_val_performance_r2)\n",
        "  print(\"test:\")\n",
        "  print(avg_performance_mae,avg_performance_msle,avg_performance_mse,avg_performance_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx9FwNB3VTqp"
      },
      "outputs": [],
      "source": [
        "AVG_result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qjb8F9kVXEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bc494c-01d8-48ea-99b6-69d6d5b21d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\\multirow{2}{*}{\\text{1.0}}}& \\text{Validation} &0.0252&0.0104&0.0271&1.2&0.847\\\\\\cline{2-7}&\\text{Test} &0.0302&0.0124&0.0333&1.36&0.8637\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{2.0}}}& \\text{Validation} &0.0178&0.0069&0.0303&0.87&0.8722\\\\\\cline{2-7}&\\text{Test} &0.0192&0.0077&0.0206&0.94&0.847\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{3.0}}}& \\text{Validation} &0.0167&0.0057&0.0187&0.8&0.9123\\\\\\cline{2-7}&\\text{Test} &0.0156&0.0053&0.015&0.76&0.8959\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{4.0}}}& \\text{Validation} &0.0124&0.0027&0.0114&0.55&0.9456\\\\\\cline{2-7}&\\text{Test} &0.0116&0.0026&0.0117&0.52&0.9663\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{5.0}}}& \\text{Validation} &0.0084&0.002&0.0063&0.4&0.9542\\\\\\cline{2-7}&\\text{Test} &0.0083&0.002&0.0063&0.39&0.9536\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{6.0}}}& \\text{Validation} &0.0094&0.0018&0.0071&0.41&0.967\\\\\\cline{2-7}&\\text{Test} &0.0095&0.0019&0.0099&0.41&0.9544\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{7.0}}}& \\text{Validation} &0.0095&0.0017&0.0107&0.41&0.9422\\\\\\cline{2-7}&\\text{Test} &0.0087&0.0016&0.0058&0.39&0.9645\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{8.0}}}& \\text{Validation} &0.0107&0.0019&0.0083&0.45&0.9679\\\\\\cline{2-7}&\\text{Test} &0.0104&0.0019&0.0075&0.44&0.9666\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{9.0}}}& \\text{Validation} &0.0085&0.0016&0.0059&0.39&0.9628\\\\\\cline{2-7}&\\text{Test} &0.0082&0.0015&0.0055&0.38&0.9611\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{10.0}}}& \\text{Validation} &0.0087&0.0015&0.0058&0.4&0.9613\\\\\\cline{2-7}&\\text{Test} &0.0089&0.0016&0.006&0.4&0.9612\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{11.0}}}& \\text{Validation} &0.0125&0.0022&0.0256&0.52&0.9541\\\\\\cline{2-7}&\\text{Test} &0.0117&0.0021&0.0093&0.5&0.9648\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{12.0}}}& \\text{Validation} &0.0094&0.0017&0.0064&0.45&0.9586\\\\\\cline{2-7}&\\text{Test} &0.01&0.0018&0.0071&0.47&0.9601\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{14.0}}}& \\text{Validation} &0.008&0.0015&0.0051&0.41&0.9499\\\\\\cline{2-7}&\\text{Test} &0.0084&0.0016&0.0056&0.42&0.9528\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{15.0}}}& \\text{Validation} &0.0097&0.0019&0.0074&0.5&0.9497\\\\\\cline{2-7}&\\text{Test} &0.009&0.0018&0.0061&0.48&0.9459\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{16.0}}}& \\text{Validation} &0.0093&0.0018&0.0063&0.5&0.9379\\\\\\cline{2-7}&\\text{Test} &0.0093&0.0018&0.0064&0.5&0.9361\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{17.0}}}& \\text{Validation} &0.0084&0.0018&0.0057&0.48&0.9253\\\\\\cline{2-7}&\\text{Test} &0.0087&0.0018&0.006&0.49&0.9264\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{18.0}}}& \\text{Validation} &0.011&0.0023&0.0099&0.51&0.9346\\\\\\cline{2-7}&\\text{Test} &0.0126&0.0025&0.0124&0.53&0.9424\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{19.0}}}& \\text{Validation} &0.0128&0.0027&0.0107&0.61&0.9248\\\\\\cline{2-7}&\\text{Test} &0.0129&0.0028&0.0113&0.61&0.9257\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{20.0}}}& \\text{Validation} &0.0078&0.0018&0.0048&0.53&0.9468\\\\\\cline{2-7}&\\text{Test} &0.008&0.0019&0.0051&0.53&0.9474\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{22.0}}}& \\text{Validation} &0.012&0.0032&0.0107&0.63&0.9505\\\\\\cline{2-7}&\\text{Test} &0.0119&0.0032&0.0106&0.62&0.9501\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{24.0}}}& \\text{Validation} &0.0113&0.003&0.0094&0.62&0.9497\\\\\\cline{2-7}&\\text{Test} &0.0118&0.0032&0.0103&0.63&0.9482\\\\\\hline\n",
            "{\\multirow{2}{*}{\\text{25.0}}}& \\text{Validation} &0.018&0.005&0.0202&0.78&0.9533\\\\\\cline{2-7}&\\text{Test} &0.0175&0.0049&0.0195&0.77&0.9505\\\\\\hline\n"
          ]
        }
      ],
      "source": [
        "#TABLE 4: Evaluation metrics of San Francisco for Proposedmodel\n",
        "#{\\multirow{2}{*}{\\text{1.0}}}& \\text{Validation} &0.0372 & 0.0151&0.0632&0.7738\\\\ \\cline{2-6}&\\text{Test} &0.0445&0.0184&0.0946&0.7886\\\\ \\hline\n",
        "for key in final_performance.keys():\n",
        "  datanow = \"{\\\\multirow{2}{*}{\\\\text{\"+str(key)+\"}}}& \\\\text{Validation} \"\n",
        "  for i in range(len(metrics_name)):\n",
        "    valueNow = round(final_val_performance[key][i] , 4)\n",
        "    datanow = datanow+\"&\"+str(valueNow)\n",
        "  datanow = datanow+'\\\\'+'\\\\'\n",
        "  datanow = datanow+'\\\\cline{2-7}&\\\\text{Test} '\n",
        "  for i in range(len(metrics_name)):\n",
        "    valueNow = round(final_performance[key][i] , 4)\n",
        "    datanow = datanow+\"&\"+str(valueNow)\n",
        "  datanow = datanow+'\\\\'+'\\\\'\n",
        "  datanow = datanow + \"\\\\hline\"\n",
        "  print(datanow)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ycHPheTMWFlH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chicago_merge_swap.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
